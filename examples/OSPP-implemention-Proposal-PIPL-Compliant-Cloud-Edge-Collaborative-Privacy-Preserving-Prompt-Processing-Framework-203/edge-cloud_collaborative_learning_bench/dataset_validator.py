#!/usr/bin/env python3
"""
ChnSentiCorp-Liteæ•°æ®é›†éªŒè¯å™¨
éªŒè¯æ•°æ®é›†è´¨é‡å’ŒPIPLåˆè§„æ€§
"""

import json
import re
from pathlib import Path
from typing import Dict, List, Any, Tuple
import numpy as np

class DatasetValidator:
    """æ•°æ®é›†éªŒè¯å™¨"""
    
    def __init__(self, data_dir: str = "./data/chnsenticorp_lite"):
        self.data_dir = Path(data_dir)
        self.validation_results = {}
    
    def load_dataset(self) -> Tuple[List[Dict], List[Dict], List[Dict]]:
        """åŠ è½½æ•°æ®é›†"""
        print("åŠ è½½æ•°æ®é›†...")
        
        # åŠ è½½è®­ç»ƒé›†
        with open(self.data_dir / "train.jsonl", "r", encoding="utf-8") as f:
            train_data = [json.loads(line) for line in f]
        
        # åŠ è½½éªŒè¯é›†
        with open(self.data_dir / "val.jsonl", "r", encoding="utf-8") as f:
            val_data = [json.loads(line) for line in f]
        
        # åŠ è½½æµ‹è¯•é›†
        with open(self.data_dir / "test.jsonl", "r", encoding="utf-8") as f:
            test_data = [json.loads(line) for line in f]
        
        print(f"æ•°æ®é›†åŠ è½½å®Œæˆ: è®­ç»ƒé›†{len(train_data)}, éªŒè¯é›†{len(val_data)}, æµ‹è¯•é›†{len(test_data)}")
        return train_data, val_data, test_data
    
    def validate_schema(self, data: List[Dict]) -> Dict[str, Any]:
        """éªŒè¯æ•°æ®æ¨¡å¼"""
        print("éªŒè¯æ•°æ®æ¨¡å¼...")
        
        required_fields = [
            "sample_id", "text", "label", "privacy_level", 
            "pii_entities", "pipl_cross_border", "privacy_budget_cost", "metadata"
        ]
        
        schema_errors = []
        valid_samples = 0
        
        for i, sample in enumerate(data):
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            missing_fields = [field for field in required_fields if field not in sample]
            if missing_fields:
                schema_errors.append(f"æ ·æœ¬{i}: ç¼ºå°‘å­—æ®µ {missing_fields}")
                continue
            
            # æ£€æŸ¥å­—æ®µç±»å‹
            if not isinstance(sample["text"], str):
                schema_errors.append(f"æ ·æœ¬{i}: textå­—æ®µç±»å‹é”™è¯¯")
                continue
            
            if sample["label"] not in ["positive", "negative"]:
                schema_errors.append(f"æ ·æœ¬{i}: labelå­—æ®µå€¼é”™è¯¯")
                continue
            
            if sample["privacy_level"] not in ["general", "high_sensitivity"]:
                schema_errors.append(f"æ ·æœ¬{i}: privacy_levelå­—æ®µå€¼é”™è¯¯")
                continue
            
            if not isinstance(sample["pii_entities"], list):
                schema_errors.append(f"æ ·æœ¬{i}: pii_entitieså­—æ®µç±»å‹é”™è¯¯")
                continue
            
            if not isinstance(sample["pipl_cross_border"], bool):
                schema_errors.append(f"æ ·æœ¬{i}: pipl_cross_borderå­—æ®µç±»å‹é”™è¯¯")
                continue
            
            if not isinstance(sample["privacy_budget_cost"], (int, float)):
                schema_errors.append(f"æ ·æœ¬{i}: privacy_budget_costå­—æ®µç±»å‹é”™è¯¯")
                continue
            
            valid_samples += 1
        
        return {
            "total_samples": len(data),
            "valid_samples": valid_samples,
            "schema_errors": schema_errors,
            "validity_rate": valid_samples / len(data) if data else 0
        }
    
    def validate_pii_detection(self, data: List[Dict]) -> Dict[str, Any]:
        """éªŒè¯PIIæ£€æµ‹å‡†ç¡®æ€§"""
        print("éªŒè¯PIIæ£€æµ‹å‡†ç¡®æ€§...")
        
        pii_patterns = {
            "PERSON": r'[å¼ ç‹æèµµåˆ˜é™ˆæ¨é»„å‘¨å´å¾å­™é©¬æœ±èƒ¡éƒ­ä½•é«˜æ—ç½—éƒ‘æ¢è°¢å®‹å”è®¸éŸ©å†¯é‚“æ›¹å½­æ›¾è§ç”°è‘£è¢æ½˜äºè’‹è”¡ä½™æœå¶ç¨‹è‹é­å•ä¸ä»»æ²ˆå§šå¢å§œå´”é’Ÿè°­é™†æ±ªèŒƒé‡‘çŸ³å»–è´¾å¤éŸ¦ä»˜æ–¹ç™½é‚¹å­Ÿç†Šç§¦é‚±æ±Ÿå°¹è–›é—«æ®µé›·ä¾¯é¾™å²é™¶é»è´ºé¡¾æ¯›éƒé¾šé‚µä¸‡é’±ä¸¥è¦ƒæ­¦æˆ´è«å­”å‘æ±¤][\u4e00-\u9fa5]{1,2}',
            "PHONE": r'1[3-9]\d{9}',
            "EMAIL": r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
            "ID_CARD": r'\d{17}[\dXx]'
        }
        
        detection_results = {
            "total_samples": len(data),
            "pii_detected_samples": 0,
            "pii_accuracy": 0,
            "entity_accuracy": {}
        }
        
        for sample in data:
            text = sample["text"]
            detected_entities = sample["pii_entities"]
            
            # æ‰‹åŠ¨æ£€æµ‹PIIå®ä½“
            manual_entities = []
            for entity_type, pattern in pii_patterns.items():
                if re.search(pattern, text):
                    manual_entities.append(entity_type)
            
            # è®¡ç®—æ£€æµ‹å‡†ç¡®æ€§
            if manual_entities or detected_entities:
                detection_results["pii_detected_samples"] += 1
                
                # è®¡ç®—å®ä½“æ£€æµ‹å‡†ç¡®æ€§
                for entity_type in pii_patterns.keys():
                    manual_detected = entity_type in manual_entities
                    auto_detected = entity_type in detected_entities
                    
                    if entity_type not in detection_results["entity_accuracy"]:
                        detection_results["entity_accuracy"][entity_type] = {"correct": 0, "total": 0}
                    
                    detection_results["entity_accuracy"][entity_type]["total"] += 1
                    if manual_detected == auto_detected:
                        detection_results["entity_accuracy"][entity_type]["correct"] += 1
        
        # è®¡ç®—æ€»ä½“å‡†ç¡®æ€§
        if detection_results["pii_detected_samples"] > 0:
            total_correct = sum(acc["correct"] for acc in detection_results["entity_accuracy"].values())
            total_entities = sum(acc["total"] for acc in detection_results["entity_accuracy"].values())
            detection_results["pii_accuracy"] = total_correct / total_entities if total_entities > 0 else 0
        
        return detection_results
    
    def validate_privacy_compliance(self, data: List[Dict]) -> Dict[str, Any]:
        """éªŒè¯éšç§åˆè§„æ€§"""
        print("ğŸ” éªŒè¯éšç§åˆè§„æ€§...")
        
        compliance_results = {
            "total_samples": len(data),
            "cross_border_samples": 0,
            "high_sensitivity_samples": 0,
            "compliance_violations": [],
            "privacy_budget_stats": {}
        }
        
        for i, sample in enumerate(data):
            # æ£€æŸ¥è·¨å¢ƒä¼ è¾“åˆè§„æ€§
            if sample["pipl_cross_border"]:
                compliance_results["cross_border_samples"] += 1
                
                # é«˜æ•æ„Ÿåº¦æ•°æ®ä¸åº”è¯¥å…è®¸è·¨å¢ƒä¼ è¾“
                if sample["privacy_level"] == "high_sensitivity":
                    compliance_results["compliance_violations"].append(
                        f"æ ·æœ¬{i}: é«˜æ•æ„Ÿåº¦æ•°æ®ä¸å…è®¸è·¨å¢ƒä¼ è¾“"
                    )
            
            # ç»Ÿè®¡é«˜æ•æ„Ÿåº¦æ ·æœ¬
            if sample["privacy_level"] == "high_sensitivity":
                compliance_results["high_sensitivity_samples"] += 1
            
            # æ£€æŸ¥éšç§é¢„ç®—æˆæœ¬åˆç†æ€§
            budget_cost = sample["privacy_budget_cost"]
            if budget_cost < 0:
                compliance_results["compliance_violations"].append(
                    f"æ ·æœ¬{i}: éšç§é¢„ç®—æˆæœ¬ä¸èƒ½ä¸ºè´Ÿæ•°"
                )
        
        # è®¡ç®—éšç§é¢„ç®—ç»Ÿè®¡
        budget_costs = [sample["privacy_budget_cost"] for sample in data]
        compliance_results["privacy_budget_stats"] = {
            "mean": round(np.mean(budget_costs), 3),
            "std": round(np.std(budget_costs), 3),
            "min": round(np.min(budget_costs), 3),
            "max": round(np.max(budget_costs), 3)
        }
        
        return compliance_results
    
    def validate_data_quality(self, data: List[Dict]) -> Dict[str, Any]:
        """éªŒè¯æ•°æ®è´¨é‡"""
        print("ğŸ” éªŒè¯æ•°æ®è´¨é‡...")
        
        quality_results = {
            "total_samples": len(data),
            "empty_text_samples": 0,
            "short_text_samples": 0,
            "long_text_samples": 0,
            "duplicate_samples": 0,
            "text_length_stats": {}
        }
        
        text_lengths = []
        text_set = set()
        
        for sample in data:
            text = sample["text"]
            text_length = len(text)
            text_lengths.append(text_length)
            
            # æ£€æŸ¥ç©ºæ–‡æœ¬
            if not text.strip():
                quality_results["empty_text_samples"] += 1
            
            # æ£€æŸ¥çŸ­æ–‡æœ¬
            if text_length < 5:
                quality_results["short_text_samples"] += 1
            
            # æ£€æŸ¥é•¿æ–‡æœ¬
            if text_length > 500:
                quality_results["long_text_samples"] += 1
            
            # æ£€æŸ¥é‡å¤æ–‡æœ¬
            if text in text_set:
                quality_results["duplicate_samples"] += 1
            else:
                text_set.add(text)
        
        # è®¡ç®—æ–‡æœ¬é•¿åº¦ç»Ÿè®¡
        if text_lengths:
            quality_results["text_length_stats"] = {
                "mean": round(np.mean(text_lengths), 2),
                "std": round(np.std(text_lengths), 2),
                "min": min(text_lengths),
                "max": max(text_lengths)
            }
        
        return quality_results
    
    def validate_dataset_balance(self, train_data: List[Dict], val_data: List[Dict], test_data: List[Dict]) -> Dict[str, Any]:
        """éªŒè¯æ•°æ®é›†å¹³è¡¡æ€§"""
        print("ğŸ” éªŒè¯æ•°æ®é›†å¹³è¡¡æ€§...")
        
        balance_results = {
            "train_size": len(train_data),
            "val_size": len(val_data),
            "test_size": len(test_data),
            "total_size": len(train_data) + len(val_data) + len(test_data),
            "split_ratios": {},
            "label_distribution": {},
            "privacy_level_distribution": {}
        }
        
        # è®¡ç®—åˆ†å‰²æ¯”ä¾‹
        total_size = balance_results["total_size"]
        balance_results["split_ratios"] = {
            "train": round(len(train_data) / total_size, 3),
            "val": round(len(val_data) / total_size, 3),
            "test": round(len(test_data) / total_size, 3)
        }
        
        # ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ
        all_data = train_data + val_data + test_data
        for sample in all_data:
            label = sample["label"]
            balance_results["label_distribution"][label] = balance_results["label_distribution"].get(label, 0) + 1
        
        # ç»Ÿè®¡éšç§çº§åˆ«åˆ†å¸ƒ
        for sample in all_data:
            level = sample["privacy_level"]
            balance_results["privacy_level_distribution"][level] = balance_results["privacy_level_distribution"].get(level, 0) + 1
        
        return balance_results
    
    def run_validation(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´éªŒè¯"""
        print("ğŸ§ª å¼€å§‹æ•°æ®é›†éªŒè¯...")
        print("="*60)
        
        # åŠ è½½æ•°æ®é›†
        train_data, val_data, test_data = self.load_dataset()
        
        # éªŒè¯æ•°æ®æ¨¡å¼
        print("\n1. éªŒè¯æ•°æ®æ¨¡å¼...")
        train_schema = self.validate_schema(train_data)
        val_schema = self.validate_schema(val_data)
        test_schema = self.validate_schema(test_data)
        
        # éªŒè¯PIIæ£€æµ‹
        print("\n2. éªŒè¯PIIæ£€æµ‹...")
        train_pii = self.validate_pii_detection(train_data)
        val_pii = self.validate_pii_detection(val_data)
        test_pii = self.validate_pii_detection(test_data)
        
        # éªŒè¯éšç§åˆè§„æ€§
        print("\n3. éªŒè¯éšç§åˆè§„æ€§...")
        train_compliance = self.validate_privacy_compliance(train_data)
        val_compliance = self.validate_privacy_compliance(val_data)
        test_compliance = self.validate_privacy_compliance(test_data)
        
        # éªŒè¯æ•°æ®è´¨é‡
        print("\n4. éªŒè¯æ•°æ®è´¨é‡...")
        train_quality = self.validate_data_quality(train_data)
        val_quality = self.validate_data_quality(val_data)
        test_quality = self.validate_data_quality(test_data)
        
        # éªŒè¯æ•°æ®é›†å¹³è¡¡æ€§
        print("\n5. éªŒè¯æ•°æ®é›†å¹³è¡¡æ€§...")
        balance = self.validate_dataset_balance(train_data, val_data, test_data)
        
        # æ±‡æ€»éªŒè¯ç»“æœ
        validation_results = {
            "schema_validation": {
                "train": train_schema,
                "val": val_schema,
                "test": test_schema
            },
            "pii_detection": {
                "train": train_pii,
                "val": val_pii,
                "test": test_pii
            },
            "privacy_compliance": {
                "train": train_compliance,
                "val": val_compliance,
                "test": test_compliance
            },
            "data_quality": {
                "train": train_quality,
                "val": val_quality,
                "test": test_quality
            },
            "dataset_balance": balance
        }
        
        return validation_results
    
    def print_validation_report(self, results: Dict[str, Any]):
        """æ‰“å°éªŒè¯æŠ¥å‘Š"""
        print("\n" + "="*80)
        print("ğŸ“Š æ•°æ®é›†éªŒè¯æŠ¥å‘Š")
        print("="*80)
        
        # æ•°æ®æ¨¡å¼éªŒè¯
        print("\n1. æ•°æ®æ¨¡å¼éªŒè¯:")
        for split, schema in results["schema_validation"].items():
            print(f"  {split}: {schema['valid_samples']}/{schema['total_samples']} æœ‰æ•ˆæ ·æœ¬")
            if schema['schema_errors']:
                print(f"    é”™è¯¯: {len(schema['schema_errors'])} ä¸ª")
        
        # PIIæ£€æµ‹éªŒè¯
        print("\n2. PIIæ£€æµ‹éªŒè¯:")
        for split, pii in results["pii_detection"].items():
            print(f"  {split}: å‡†ç¡®æ€§ {pii['pii_accuracy']:.3f}")
            for entity, acc in pii['entity_accuracy'].items():
                accuracy = acc['correct'] / acc['total'] if acc['total'] > 0 else 0
                print(f"    {entity}: {accuracy:.3f}")
        
        # éšç§åˆè§„æ€§éªŒè¯
        print("\n3. éšç§åˆè§„æ€§éªŒè¯:")
        for split, compliance in results["privacy_compliance"].items():
            print(f"  {split}: è·¨å¢ƒä¼ è¾“ {compliance['cross_border_samples']} ä¸ª")
            print(f"    é«˜æ•æ„Ÿåº¦: {compliance['high_sensitivity_samples']} ä¸ª")
            if compliance['compliance_violations']:
                print(f"    åˆè§„è¿è§„: {len(compliance['compliance_violations'])} ä¸ª")
        
        # æ•°æ®è´¨é‡éªŒè¯
        print("\n4. æ•°æ®è´¨é‡éªŒè¯:")
        for split, quality in results["data_quality"].items():
            print(f"  {split}: ç©ºæ–‡æœ¬ {quality['empty_text_samples']} ä¸ª")
            print(f"    çŸ­æ–‡æœ¬: {quality['short_text_samples']} ä¸ª")
            print(f"    é•¿æ–‡æœ¬: {quality['long_text_samples']} ä¸ª")
            print(f"    é‡å¤æ–‡æœ¬: {quality['duplicate_samples']} ä¸ª")
        
        # æ•°æ®é›†å¹³è¡¡æ€§éªŒè¯
        print("\n5. æ•°æ®é›†å¹³è¡¡æ€§éªŒè¯:")
        balance = results["dataset_balance"]
        print(f"  æ€»æ ·æœ¬æ•°: {balance['total_size']}")
        print(f"  åˆ†å‰²æ¯”ä¾‹: è®­ç»ƒé›†{balance['split_ratios']['train']}, éªŒè¯é›†{balance['split_ratios']['val']}, æµ‹è¯•é›†{balance['split_ratios']['test']}")
        print(f"  æ ‡ç­¾åˆ†å¸ƒ: {balance['label_distribution']}")
        print(f"  éšç§çº§åˆ«åˆ†å¸ƒ: {balance['privacy_level_distribution']}")
        
        print("="*80)

def main():
    """ä¸»å‡½æ•°"""
    print("ChnSentiCorp-Liteæ•°æ®é›†éªŒè¯å™¨")
    print("éªŒè¯æ•°æ®é›†è´¨é‡å’ŒPIPLåˆè§„æ€§")
    print("="*60)
    
    # åˆ›å»ºéªŒè¯å™¨
    validator = DatasetValidator()
    
    # è¿è¡ŒéªŒè¯
    results = validator.run_validation()
    
    # æ‰“å°éªŒè¯æŠ¥å‘Š
    validator.print_validation_report(results)
    
    # ä¿å­˜éªŒè¯ç»“æœ
    with open("./data/chnsenticorp_lite/validation_report.json", "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print("\nğŸ‰ æ•°æ®é›†éªŒè¯å®Œæˆï¼")
    print("éªŒè¯æŠ¥å‘Šå·²ä¿å­˜åˆ°: validation_report.json")

if __name__ == "__main__":
    main()
