#!/usr/bin/env python3
"""
PIPLéšç§ä¿æŠ¤LLMæ¡†æ¶ - å®Œæ•´åŠŸèƒ½æµ‹è¯•

æœ¬è„šæœ¬æä¾›å…¨é¢çš„åŠŸèƒ½æµ‹è¯•ï¼ŒéªŒè¯PIPLéšç§ä¿æŠ¤LLMæ¡†æ¶çš„æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½ï¼š
- PIIæ£€æµ‹åŠŸèƒ½æµ‹è¯•
- å·®åˆ†éšç§ä¿æŠ¤æµ‹è¯•
- åˆè§„æ€§ç›‘æ§æµ‹è¯•
- ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹æµ‹è¯•
- æ€§èƒ½åŸºå‡†æµ‹è¯•
- é”™è¯¯å¤„ç†æµ‹è¯•

ä½¿ç”¨æ–¹æ³•:
1. åœ¨Colabç¯å¢ƒä¸­è¿è¡Œæ­¤è„šæœ¬
2. ç¡®ä¿å·²åŠ è½½Qwen2.5-7Bæ¨¡å‹å’ŒPIPLé›†æˆä»£ç 
3. æŸ¥çœ‹è¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Š

ä½œè€…: PIPL Framework Team
ç‰ˆæœ¬: 1.0.0
æ—¥æœŸ: 2025-10-23
"""

import sys
import os
import json
import time
import numpy as np
import pandas as pd
from typing import Dict, List, Any, Tuple
import traceback

class ComprehensiveFunctionalTest:
    """å®Œæ•´åŠŸèƒ½æµ‹è¯•ç±»"""
    
    def __init__(self):
        self.test_results = {}
        self.test_cases = []
        self.performance_metrics = {}
        self.error_logs = []
        
    def print_test_header(self, test_name: str):
        """æ‰“å°æµ‹è¯•æ ‡é¢˜"""
        print("\n" + "="*80)
        print(f"ğŸ§ª {test_name}")
        print("="*80)
    
    def print_test_result(self, test_name: str, success: bool, details: str = ""):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"{status} {test_name}")
        if details:
            print(f"   è¯¦æƒ…: {details}")
    
    def test_pii_detection(self, privacy_qwen):
        """æµ‹è¯•PIIæ£€æµ‹åŠŸèƒ½"""
        self.print_test_header("PIIæ£€æµ‹åŠŸèƒ½æµ‹è¯•")
        
        test_cases = [
            {
                'text': 'ç”¨æˆ·å¼ ä¸‰ï¼Œç”µè¯13812345678ï¼Œé‚®ç®±zhangsan@example.com',
                'expected_pii': ['name', 'phone', 'email'],
                'description': 'åŒ…å«å¤šç§PIIä¿¡æ¯'
            },
            {
                'text': 'èº«ä»½è¯å·ç ï¼š110101199001011234',
                'expected_pii': ['id_card'],
                'description': 'èº«ä»½è¯å·ç æ£€æµ‹'
            },
            {
                'text': 'è¿™ä¸ªäº§å“å¾ˆä¸é”™ï¼Œæˆ‘å¾ˆæ»¡æ„ã€‚',
                'expected_pii': [],
                'description': 'æ— PIIä¿¡æ¯'
            },
            {
                'text': 'æå››è§‰å¾—è¿™ä¸ªæœåŠ¡å¾ˆç³Ÿç³•ï¼Œå®Œå…¨ä¸æ¨èã€‚',
                'expected_pii': ['name'],
                'description': 'ä¸­æ–‡å§“åæ£€æµ‹'
            }
        ]
        
        results = []
        for i, case in enumerate(test_cases):
            try:
                # ä½¿ç”¨PIIæ£€æµ‹å™¨
                pii_result = privacy_qwen.pii_detector.detect(case['text'])
                detected_types = [pii['type'] for pii in pii_result]
                
                # éªŒè¯æ£€æµ‹ç»“æœ
                success = set(detected_types) == set(case['expected_pii'])
                
                self.print_test_result(
                    f"æµ‹è¯•æ¡ˆä¾‹ {i+1}: {case['description']}",
                    success,
                    f"æ£€æµ‹åˆ°: {detected_types}, æœŸæœ›: {case['expected_pii']}"
                )
                
                results.append({
                    'case': case,
                    'detected': detected_types,
                    'expected': case['expected_pii'],
                    'success': success,
                    'pii_count': len(pii_result)
                })
                
            except Exception as e:
                self.print_test_result(f"æµ‹è¯•æ¡ˆä¾‹ {i+1}: {case['description']}", False, f"é”™è¯¯: {e}")
                results.append({
                    'case': case,
                    'error': str(e),
                    'success': False
                })
        
        # ç»Ÿè®¡ç»“æœ
        successful = len([r for r in results if r.get('success', False)])
        total = len(results)
        
        self.test_results['pii_detection'] = {
            'total_tests': total,
            'successful_tests': successful,
            'success_rate': successful / total * 100,
            'results': results
        }
        
        print(f"\nğŸ“Š PIIæ£€æµ‹æµ‹è¯•æ€»ç»“: {successful}/{total} é€šè¿‡ ({successful/total*100:.1f}%)")
        return results
    
    def test_differential_privacy(self, privacy_qwen):
        """æµ‹è¯•å·®åˆ†éšç§åŠŸèƒ½"""
        self.print_test_header("å·®åˆ†éšç§åŠŸèƒ½æµ‹è¯•")
        
        test_cases = [
            {
                'data': np.array([0.1, 0.2, 0.3, 0.4, 0.5]),
                'epsilon': 1.0,
                'description': 'åŸºç¡€å·®åˆ†éšç§æµ‹è¯•'
            },
            {
                'data': np.array([1.0, 2.0, 3.0, 4.0, 5.0]),
                'epsilon': 0.5,
                'description': 'é«˜éšç§ä¿æŠ¤æµ‹è¯•'
            },
            {
                'data': np.array([0.01, 0.02, 0.03, 0.04, 0.05]),
                'epsilon': 2.0,
                'description': 'ä½éšç§ä¿æŠ¤æµ‹è¯•'
            }
        ]
        
        results = []
        for i, case in enumerate(test_cases):
            try:
                # æµ‹è¯•å·®åˆ†éšç§
                original_data = case['data'].copy()
                noisy_data = privacy_qwen.differential_privacy.add_noise(original_data, case['epsilon'])
                
                # éªŒè¯å™ªå£°æ·»åŠ 
                noise_added = not np.array_equal(original_data, noisy_data)
                noise_magnitude = np.linalg.norm(noisy_data - original_data)
                
                success = noise_added and noise_magnitude > 0
                
                self.print_test_result(
                    f"æµ‹è¯•æ¡ˆä¾‹ {i+1}: {case['description']}",
                    success,
                    f"å™ªå£°å¹…åº¦: {noise_magnitude:.4f}, Epsilon: {case['epsilon']}"
                )
                
                results.append({
                    'case': case,
                    'original_data': original_data,
                    'noisy_data': noisy_data,
                    'noise_magnitude': noise_magnitude,
                    'success': success
                })
                
            except Exception as e:
                self.print_test_result(f"æµ‹è¯•æ¡ˆä¾‹ {i+1}: {case['description']}", False, f"é”™è¯¯: {e}")
                results.append({
                    'case': case,
                    'error': str(e),
                    'success': False
                })
        
        # ç»Ÿè®¡ç»“æœ
        successful = len([r for r in results if r.get('success', False)])
        total = len(results)
        
        self.test_results['differential_privacy'] = {
            'total_tests': total,
            'successful_tests': successful,
            'success_rate': successful / total * 100,
            'results': results
        }
        
        print(f"\nğŸ“Š å·®åˆ†éšç§æµ‹è¯•æ€»ç»“: {successful}/{total} é€šè¿‡ ({successful/total*100:.1f}%)")
        return results
    
    def test_compliance_monitoring(self, privacy_qwen):
        """æµ‹è¯•åˆè§„æ€§ç›‘æ§åŠŸèƒ½"""
        self.print_test_header("åˆè§„æ€§ç›‘æ§åŠŸèƒ½æµ‹è¯•")
        
        test_cases = [
            {
                'data': {'type': 'personal_info', 'risk_level': 'low', 'cross_border': False},
                'expected_status': 'compliant',
                'description': 'ä½é£é™©åˆè§„æµ‹è¯•'
            },
            {
                'data': {'type': 'sensitive_info', 'risk_level': 'high', 'cross_border': False},
                'expected_status': 'non_compliant',
                'description': 'é«˜é£é™©åˆè§„æµ‹è¯•'
            },
            {
                'data': {'type': 'general', 'risk_level': 'medium', 'cross_border': True},
                'expected_status': 'compliant',
                'description': 'è·¨å¢ƒä¼ è¾“æµ‹è¯•'
            }
        ]
        
        results = []
        for i, case in enumerate(test_cases):
            try:
                # æµ‹è¯•åˆè§„æ€§æ£€æŸ¥
                compliance = privacy_qwen.compliance_monitor.check_compliance(case['data'])
                
                # éªŒè¯åˆè§„çŠ¶æ€
                success = compliance['status'] == case['expected_status']
                
                self.print_test_result(
                    f"æµ‹è¯•æ¡ˆä¾‹ {i+1}: {case['description']}",
                    success,
                    f"çŠ¶æ€: {compliance['status']}, æœŸæœ›: {case['expected_status']}"
                )
                
                results.append({
                    'case': case,
                    'compliance': compliance,
                    'success': success
                })
                
            except Exception as e:
                self.print_test_result(f"æµ‹è¯•æ¡ˆä¾‹ {i+1}: {case['description']}", False, f"é”™è¯¯: {e}")
                results.append({
                    'case': case,
                    'error': str(e),
                    'success': False
                })
        
        # æµ‹è¯•æ“ä½œè®°å½•
        try:
            operation = {
                'operation_id': 'test_operation',
                'operation_type': 'compliance_test',
                'user_id': 'test_user',
                'data_type': 'test_data'
            }
            log_success = privacy_qwen.compliance_monitor.log_operation(operation)
            
            self.print_test_result("æ“ä½œè®°å½•æµ‹è¯•", log_success, "æ“ä½œè®°å½•åŠŸèƒ½æ­£å¸¸")
            
        except Exception as e:
            self.print_test_result("æ“ä½œè®°å½•æµ‹è¯•", False, f"é”™è¯¯: {e}")
        
        # ç»Ÿè®¡ç»“æœ
        successful = len([r for r in results if r.get('success', False)])
        total = len(results)
        
        self.test_results['compliance_monitoring'] = {
            'total_tests': total,
            'successful_tests': successful,
            'success_rate': successful / total * 100,
            'results': results
        }
        
        print(f"\nğŸ“Š åˆè§„æ€§ç›‘æ§æµ‹è¯•æ€»ç»“: {successful}/{total} é€šè¿‡ ({successful/total*100:.1f}%)")
        return results
    
    def test_end_to_end_workflow(self, privacy_qwen):
        """æµ‹è¯•ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹"""
        self.print_test_header("ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹æµ‹è¯•")
        
        test_cases = [
            {
                'text': 'è¯·ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†å²ã€‚',
                'expected_risk': 'low',
                'description': 'æ™®é€šæ–‡æœ¬å¤„ç†'
            },
            {
                'text': 'ç”¨æˆ·å¼ ä¸‰ï¼Œç”µè¯13812345678ï¼Œå¯¹è¿™ä¸ªäº§å“å¾ˆæ»¡æ„ã€‚',
                'expected_risk': 'high',
                'description': 'åŒ…å«PIIçš„æ–‡æœ¬å¤„ç†'
            },
            {
                'text': 'æå››è§‰å¾—è¿™ä¸ªæœåŠ¡å¾ˆç³Ÿç³•ï¼Œå®Œå…¨ä¸æ¨èã€‚',
                'expected_risk': 'medium',
                'description': 'åŒ…å«å§“åçš„æ–‡æœ¬å¤„ç†'
            },
            {
                'text': 'æ•´ä½“æ¥è¯´æ¯”è¾ƒæ»¡æ„ï¼Œä¼šç»§ç»­ä½¿ç”¨ã€‚',
                'expected_risk': 'low',
                'description': 'æ— æ•æ„Ÿä¿¡æ¯æ–‡æœ¬å¤„ç†'
            }
        ]
        
        results = []
        for i, case in enumerate(test_cases):
            try:
                # æ‰§è¡Œç«¯åˆ°ç«¯å¤„ç†
                result = privacy_qwen.generate_with_privacy_protection(case['text'])
                
                # éªŒè¯å¤„ç†ç»“æœ
                success = (
                    result.get('status') == 'success' and
                    result.get('risk_level') == case['expected_risk'] and
                    'response' in result and
                    'compliance' in result
                )
                
                self.print_test_result(
                    f"æµ‹è¯•æ¡ˆä¾‹ {i+1}: {case['description']}",
                    success,
                    f"é£é™©çº§åˆ«: {result.get('risk_level')}, å“åº”é•¿åº¦: {len(result.get('response', ''))}"
                )
                
                results.append({
                    'case': case,
                    'result': result,
                    'success': success
                })
                
            except Exception as e:
                self.print_test_result(f"æµ‹è¯•æ¡ˆä¾‹ {i+1}: {case['description']}", False, f"é”™è¯¯: {e}")
                results.append({
                    'case': case,
                    'error': str(e),
                    'success': False
                })
        
        # ç»Ÿè®¡ç»“æœ
        successful = len([r for r in results if r.get('success', False)])
        total = len(results)
        
        self.test_results['end_to_end_workflow'] = {
            'total_tests': total,
            'successful_tests': successful,
            'success_rate': successful / total * 100,
            'results': results
        }
        
        print(f"\nğŸ“Š ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹æµ‹è¯•æ€»ç»“: {successful}/{total} é€šè¿‡ ({successful/total*100:.1f}%)")
        return results
    
    def test_performance_benchmark(self, privacy_qwen):
        """æµ‹è¯•æ€§èƒ½åŸºå‡†"""
        self.print_test_header("æ€§èƒ½åŸºå‡†æµ‹è¯•")
        
        test_cases = [
            {'text': 'è¯·ä»‹ç»ä¸€ä¸‹æœºå™¨å­¦ä¹ ã€‚', 'iterations': 5},
            {'text': 'ç”¨æˆ·å¼ ä¸‰ï¼Œç”µè¯13812345678ï¼Œå¯¹è¿™ä¸ªäº§å“å¾ˆæ»¡æ„ã€‚', 'iterations': 3},
            {'text': 'è¿™ä¸ªæœåŠ¡å¾ˆä¸é”™ï¼Œæ¨èä½¿ç”¨ã€‚', 'iterations': 5}
        ]
        
        performance_results = []
        
        for i, case in enumerate(test_cases):
            try:
                print(f"æ‰§è¡Œæ€§èƒ½æµ‹è¯• {i+1}: {case['text'][:20]}...")
                
                times = []
                for j in range(case['iterations']):
                    start_time = time.time()
                    result = privacy_qwen.generate_with_privacy_protection(case['text'])
                    end_time = time.time()
                    
                    if result.get('status') == 'success':
                        times.append(end_time - start_time)
                
                if times:
                    avg_time = np.mean(times)
                    std_time = np.std(times)
                    min_time = np.min(times)
                    max_time = np.max(times)
                    
                    self.print_test_result(
                        f"æ€§èƒ½æµ‹è¯• {i+1}",
                        True,
                        f"å¹³å‡æ—¶é—´: {avg_time:.3f}s, æ ‡å‡†å·®: {std_time:.3f}s"
                    )
                    
                    performance_results.append({
                        'case': case,
                        'avg_time': avg_time,
                        'std_time': std_time,
                        'min_time': min_time,
                        'max_time': max_time,
                        'iterations': len(times)
                    })
                else:
                    self.print_test_result(f"æ€§èƒ½æµ‹è¯• {i+1}", False, "æ‰€æœ‰è¿­ä»£éƒ½å¤±è´¥")
                    
            except Exception as e:
                self.print_test_result(f"æ€§èƒ½æµ‹è¯• {i+1}", False, f"é”™è¯¯: {e}")
        
        # è®°å½•æ€§èƒ½æŒ‡æ ‡
        self.performance_metrics = {
            'test_cases': len(test_cases),
            'results': performance_results
        }
        
        print(f"\nğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆ: {len(performance_results)} ä¸ªæµ‹è¯•æ¡ˆä¾‹")
        return performance_results
    
    def test_error_handling(self, privacy_qwen):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        self.print_test_header("é”™è¯¯å¤„ç†æµ‹è¯•")
        
        test_cases = [
            {
                'input': None,
                'expected_error': True,
                'description': 'ç©ºè¾“å…¥æµ‹è¯•'
            },
            {
                'input': '',
                'expected_error': False,
                'description': 'ç©ºå­—ç¬¦ä¸²æµ‹è¯•'
            },
            {
                'input': 'a' * 10000,
                'expected_error': False,
                'description': 'è¶…é•¿æ–‡æœ¬æµ‹è¯•'
            }
        ]
        
        results = []
        for i, case in enumerate(test_cases):
            try:
                if case['input'] is None:
                    # æµ‹è¯•ç©ºè¾“å…¥
                    try:
                        result = privacy_qwen.generate_with_privacy_protection(None)
                        error_handled = result.get('status') == 'failed'
                    except:
                        error_handled = True
                else:
                    # æµ‹è¯•æ­£å¸¸è¾“å…¥
                    result = privacy_qwen.generate_with_privacy_protection(case['input'])
                    error_handled = result.get('status') != 'failed'
                
                success = error_handled == case['expected_error']
                
                self.print_test_result(
                    f"æµ‹è¯•æ¡ˆä¾‹ {i+1}: {case['description']}",
                    success,
                    f"é”™è¯¯å¤„ç†: {'æ­£å¸¸' if error_handled else 'å¼‚å¸¸'}"
                )
                
                results.append({
                    'case': case,
                    'error_handled': error_handled,
                    'success': success
                })
                
            except Exception as e:
                self.print_test_result(f"æµ‹è¯•æ¡ˆä¾‹ {i+1}: {case['description']}", False, f"é”™è¯¯: {e}")
                results.append({
                    'case': case,
                    'error': str(e),
                    'success': False
                })
        
        # ç»Ÿè®¡ç»“æœ
        successful = len([r for r in results if r.get('success', False)])
        total = len(results)
        
        self.test_results['error_handling'] = {
            'total_tests': total,
            'successful_tests': successful,
            'success_rate': successful / total * 100,
            'results': results
        }
        
        print(f"\nğŸ“Š é”™è¯¯å¤„ç†æµ‹è¯•æ€»ç»“: {successful}/{total} é€šè¿‡ ({successful/total*100:.1f}%)")
        return results
    
    def test_batch_processing(self, privacy_qwen):
        """æµ‹è¯•æ‰¹é‡å¤„ç†"""
        self.print_test_header("æ‰¹é‡å¤„ç†æµ‹è¯•")
        
        batch_texts = [
            "è¿™ä¸ªäº§å“å¾ˆä¸é”™ã€‚",
            "å¼ ä¸‰è§‰å¾—æœåŠ¡å¾ˆå·®ã€‚",
            "æ•´ä½“æ¯”è¾ƒæ»¡æ„ã€‚",
            "ç”¨æˆ·æå››ï¼Œç”µè¯13987654321ï¼Œå¯¹è¿™ä¸ªäº§å“å¾ˆæ»¡æ„ã€‚",
            "è¿™ä¸ªæœåŠ¡å€¼å¾—æ¨èã€‚"
        ]
        
        try:
            # æ‰§è¡Œæ‰¹é‡å¤„ç†
            results = []
            for i, text in enumerate(batch_texts):
                result = privacy_qwen.generate_with_privacy_protection(text)
                result['batch_index'] = i
                results.append(result)
            
            # ç»Ÿè®¡ç»“æœ
            successful = len([r for r in results if r.get('status') == 'success'])
            total = len(results)
            
            self.print_test_result(
                "æ‰¹é‡å¤„ç†æµ‹è¯•",
                successful == total,
                f"æˆåŠŸ: {successful}/{total}"
            )
            
            # æ˜¾ç¤ºæ‰¹é‡å¤„ç†ç»“æœ
            print("\nğŸ“‹ æ‰¹é‡å¤„ç†ç»“æœ:")
            for i, result in enumerate(results):
                status = "âœ…" if result.get('status') == 'success' else "âŒ"
                risk = result.get('risk_level', 'unknown')
                print(f"  {status} æ¡ˆä¾‹ {i+1}: é£é™©çº§åˆ« {risk}")
            
            self.test_results['batch_processing'] = {
                'total_tests': total,
                'successful_tests': successful,
                'success_rate': successful / total * 100,
                'results': results
            }
            
            return results
            
        except Exception as e:
            self.print_test_result("æ‰¹é‡å¤„ç†æµ‹è¯•", False, f"é”™è¯¯: {e}")
            return []
    
    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š"""
        self.print_test_header("ç»¼åˆæµ‹è¯•æŠ¥å‘Š")
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        total_tests = sum(result['total_tests'] for result in self.test_results.values())
        total_successful = sum(result['successful_tests'] for result in self.test_results.values())
        overall_success_rate = (total_successful / total_tests * 100) if total_tests > 0 else 0
        
        print(f"ğŸ“Š æ€»ä½“æµ‹è¯•ç»Ÿè®¡:")
        print(f"  æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"  æˆåŠŸæµ‹è¯•: {total_successful}")
        print(f"  æˆåŠŸç‡: {overall_success_rate:.1f}%")
        
        print(f"\nğŸ“‹ å„æ¨¡å—æµ‹è¯•ç»“æœ:")
        for module, result in self.test_results.items():
            print(f"  {module}: {result['successful_tests']}/{result['total_tests']} ({result['success_rate']:.1f}%)")
        
        # æ€§èƒ½ç»Ÿè®¡
        if self.performance_metrics:
            print(f"\nâš¡ æ€§èƒ½ç»Ÿè®¡:")
            for result in self.performance_metrics['results']:
                print(f"  å¹³å‡å“åº”æ—¶é—´: {result['avg_time']:.3f}s")
                print(f"  å“åº”æ—¶é—´æ ‡å‡†å·®: {result['std_time']:.3f}s")
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        report = {
            'test_time': time.strftime('%Y-%m-%d %H:%M:%S'),
            'overall_statistics': {
                'total_tests': total_tests,
                'successful_tests': total_successful,
                'success_rate': overall_success_rate
            },
            'module_results': self.test_results,
            'performance_metrics': self.performance_metrics,
            'test_summary': {
                'pii_detection': self.test_results.get('pii_detection', {}).get('success_rate', 0),
                'differential_privacy': self.test_results.get('differential_privacy', {}).get('success_rate', 0),
                'compliance_monitoring': self.test_results.get('compliance_monitoring', {}).get('success_rate', 0),
                'end_to_end_workflow': self.test_results.get('end_to_end_workflow', {}).get('success_rate', 0),
                'error_handling': self.test_results.get('error_handling', {}).get('success_rate', 0),
                'batch_processing': self.test_results.get('batch_processing', {}).get('success_rate', 0)
            }
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = 'comprehensive_test_report.json'
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ è¯¦ç»†æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        return report
    
    def run_all_tests(self, privacy_qwen):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹å®Œæ•´åŠŸèƒ½æµ‹è¯•")
        print("="*80)
        
        start_time = time.time()
        
        try:
            # 1. PIIæ£€æµ‹æµ‹è¯•
            self.test_pii_detection(privacy_qwen)
            
            # 2. å·®åˆ†éšç§æµ‹è¯•
            self.test_differential_privacy(privacy_qwen)
            
            # 3. åˆè§„æ€§ç›‘æ§æµ‹è¯•
            self.test_compliance_monitoring(privacy_qwen)
            
            # 4. ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹æµ‹è¯•
            self.test_end_to_end_workflow(privacy_qwen)
            
            # 5. æ€§èƒ½åŸºå‡†æµ‹è¯•
            self.test_performance_benchmark(privacy_qwen)
            
            # 6. é”™è¯¯å¤„ç†æµ‹è¯•
            self.test_error_handling(privacy_qwen)
            
            # 7. æ‰¹é‡å¤„ç†æµ‹è¯•
            self.test_batch_processing(privacy_qwen)
            
            # 8. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
            report = self.generate_comprehensive_report()
            
            end_time = time.time()
            total_time = end_time - start_time
            
            print(f"\nğŸ‰ å®Œæ•´åŠŸèƒ½æµ‹è¯•å®Œæˆ!")
            print(f"â±ï¸ æ€»è€—æ—¶: {total_time:.2f} ç§’")
            print(f"ğŸ“Š æ€»ä½“æˆåŠŸç‡: {report['overall_statistics']['success_rate']:.1f}%")
            
            return report
            
        except Exception as e:
            print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            traceback.print_exc()
            return None

def main():
    """ä¸»å‡½æ•°"""
    print("PIPLéšç§ä¿æŠ¤LLMæ¡†æ¶ - å®Œæ•´åŠŸèƒ½æµ‹è¯•")
    print("="*80)
    
    # æ£€æŸ¥æ˜¯å¦å·²åŠ è½½æ¨¡å‹å’Œé›†æˆä»£ç 
    try:
        # å‡è®¾privacy_qwenå·²ç»åˆ›å»º
        if 'privacy_qwen' not in globals():
            print("âŒ è¯·å…ˆè¿è¡ŒPIPLé›†æˆä»£ç åˆ›å»ºprivacy_qwenå¯¹è±¡")
            print("è¯·è¿è¡Œ: exec(open('colab_pipl_integration.py').read())")
            return
        
        # åˆ›å»ºæµ‹è¯•å®ä¾‹
        test_suite = ComprehensiveFunctionalTest()
        
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        report = test_suite.run_all_tests(privacy_qwen)
        
        if report:
            print("\nğŸ‰ æµ‹è¯•å®Œæˆï¼è¯·æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Šäº†è§£æµ‹è¯•ç»“æœã€‚")
        else:
            print("\nâŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•åˆå§‹åŒ–å¤±è´¥: {e}")
        traceback.print_exc()

if __name__ == "__main__":
    main()
