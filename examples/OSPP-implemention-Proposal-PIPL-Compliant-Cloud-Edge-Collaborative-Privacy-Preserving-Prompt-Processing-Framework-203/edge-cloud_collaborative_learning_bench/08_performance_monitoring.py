#!/usr/bin/env python3
"""
é˜¶æ®µ8: æ€§èƒ½ç›‘æ§

ç›‘æ§ç³»ç»Ÿæ€§èƒ½ï¼ŒåŒ…æ‹¬CPUã€å†…å­˜ã€GPUä½¿ç”¨ç‡ï¼Œä»¥åŠéšç§ä¿æŠ¤æ•ˆæœå’Œåˆè§„æ€§çŠ¶æ€
"""

import os
import sys
import json
import time
import logging
import numpy as np
import psutil
from datetime import datetime
from typing import Dict, Any, List, Optional
import warnings
warnings.filterwarnings("ignore")

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        """åˆå§‹åŒ–æ€§èƒ½ç›‘æ§å™¨"""
        self.config = config
        self.monitoring_interval = config.get("monitoring_interval", 1.0)
        self.metrics_history = []
        self.start_time = datetime.now()
        
    def collect_system_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        # CPUä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=1)
        cpu_count = psutil.cpu_count()
        
        # å†…å­˜ä½¿ç”¨æƒ…å†µ
        memory = psutil.virtual_memory()
        memory_percent = memory.percent
        memory_used_gb = memory.used / (1024**3)
        memory_total_gb = memory.total / (1024**3)
        
        # ç£ç›˜ä½¿ç”¨æƒ…å†µ
        disk = psutil.disk_usage('/')
        disk_percent = (disk.used / disk.total) * 100
        disk_used_gb = disk.used / (1024**3)
        disk_total_gb = disk.total / (1024**3)
        
        # GPUä½¿ç”¨æƒ…å†µï¼ˆå¦‚æœå¯ç”¨ï¼‰
        gpu_usage = 0.0
        try:
            import torch
            if torch.cuda.is_available():
                gpu_usage = torch.cuda.memory_allocated() / torch.cuda.max_memory_allocated() * 100
        except ImportError:
            pass
        
        return {
            "timestamp": datetime.now().isoformat(),
            "cpu": {
                "usage_percent": cpu_percent,
                "count": cpu_count,
                "status": "normal" if cpu_percent < 80 else "high" if cpu_percent < 95 else "critical"
            },
            "memory": {
                "usage_percent": memory_percent,
                "used_gb": memory_used_gb,
                "total_gb": memory_total_gb,
                "status": "normal" if memory_percent < 80 else "high" if memory_percent < 95 else "critical"
            },
            "disk": {
                "usage_percent": disk_percent,
                "used_gb": disk_used_gb,
                "total_gb": disk_total_gb,
                "status": "normal" if disk_percent < 80 else "high" if disk_percent < 95 else "critical"
            },
            "gpu": {
                "usage_percent": gpu_usage,
                "status": "normal" if gpu_usage < 80 else "high" if gpu_usage < 95 else "critical"
            }
        }
    
    def collect_privacy_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†éšç§ä¿æŠ¤æŒ‡æ ‡"""
        # æ¨¡æ‹Ÿéšç§ä¿æŠ¤æŒ‡æ ‡
        pii_detection_rate = np.random.uniform(0.85, 0.98)
        privacy_protection_rate = np.random.uniform(0.80, 0.95)
        privacy_budget_usage = np.random.uniform(0.6, 0.9)
        compliance_violations = np.random.randint(0, 3)
        
        return {
            "timestamp": datetime.now().isoformat(),
            "pii_detection_rate": pii_detection_rate,
            "privacy_protection_rate": privacy_protection_rate,
            "privacy_budget_usage": privacy_budget_usage,
            "compliance_violations": compliance_violations,
            "privacy_score": (pii_detection_rate + privacy_protection_rate) / 2,
            "status": "good" if compliance_violations == 0 else "warning" if compliance_violations < 2 else "critical"
        }
    
    def collect_compliance_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†åˆè§„æ€§æŒ‡æ ‡"""
        # æ¨¡æ‹Ÿåˆè§„æ€§æŒ‡æ ‡
        pipl_compliance_rate = np.random.uniform(0.95, 1.0)
        cross_border_violations = np.random.randint(0, 2)
        total_violations = np.random.randint(0, 3)
        
        return {
            "timestamp": datetime.now().isoformat(),
            "pipl_compliance_rate": pipl_compliance_rate,
            "cross_border_violations": cross_border_violations,
            "total_violations": total_violations,
            "compliance_score": pipl_compliance_rate * (1 - total_violations * 0.1),
            "status": "compliant" if total_violations == 0 else "non_compliant"
        }
    
    def collect_workflow_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†å·¥ä½œæµæŒ‡æ ‡"""
        # æ¨¡æ‹Ÿå·¥ä½œæµæŒ‡æ ‡
        total_requests = np.random.randint(50, 200)
        successful_requests = int(total_requests * np.random.uniform(0.85, 0.98))
        failed_requests = total_requests - successful_requests
        success_rate = successful_requests / total_requests
        average_processing_time = np.random.uniform(0.2, 0.8)
        
        return {
            "timestamp": datetime.now().isoformat(),
            "total_requests": total_requests,
            "successful_requests": successful_requests,
            "failed_requests": failed_requests,
            "success_rate": success_rate,
            "average_processing_time": average_processing_time,
            "throughput": successful_requests / 60,  # æ¯åˆ†é’Ÿå¤„ç†æ•°
            "status": "good" if success_rate > 0.9 else "warning" if success_rate > 0.8 else "critical"
        }
    
    def collect_all_metrics(self) -> Dict[str, Any]:
        """æ”¶é›†æ‰€æœ‰æŒ‡æ ‡"""
        print("ğŸ“Š æ”¶é›†ç³»ç»ŸæŒ‡æ ‡...")
        
        all_metrics = {
            "timestamp": datetime.now().isoformat(),
            "system_metrics": self.collect_system_metrics(),
            "privacy_metrics": self.collect_privacy_metrics(),
            "compliance_metrics": self.collect_compliance_metrics(),
            "workflow_metrics": self.collect_workflow_metrics()
        }
        
        # è®¡ç®—ç»¼åˆè¯„åˆ†
        system_score = self._calculate_system_score(all_metrics["system_metrics"])
        privacy_score = self._calculate_privacy_score(all_metrics["privacy_metrics"])
        compliance_score = self._calculate_compliance_score(all_metrics["compliance_metrics"])
        workflow_score = self._calculate_workflow_score(all_metrics["workflow_metrics"])
        
        overall_score = (system_score + privacy_score + compliance_score + workflow_score) / 4
        
        all_metrics["overall_score"] = overall_score
        all_metrics["overall_status"] = self._get_overall_status(overall_score)
        
        # æ·»åŠ åˆ°å†å²è®°å½•
        self.metrics_history.append(all_metrics)
        
        return all_metrics
    
    def _calculate_system_score(self, system_metrics: Dict[str, Any]) -> float:
        """è®¡ç®—ç³»ç»Ÿè¯„åˆ†"""
        cpu_score = max(0, 100 - system_metrics["cpu"]["usage_percent"])
        memory_score = max(0, 100 - system_metrics["memory"]["usage_percent"])
        disk_score = max(0, 100 - system_metrics["disk"]["usage_percent"])
        gpu_score = max(0, 100 - system_metrics["gpu"]["usage_percent"])
        
        return (cpu_score + memory_score + disk_score + gpu_score) / 4
    
    def _calculate_privacy_score(self, privacy_metrics: Dict[str, Any]) -> float:
        """è®¡ç®—éšç§è¯„åˆ†"""
        pii_score = privacy_metrics["pii_detection_rate"] * 100
        protection_score = privacy_metrics["privacy_protection_rate"] * 100
        budget_score = max(0, 100 - privacy_metrics["privacy_budget_usage"] * 100)
        violation_penalty = privacy_metrics["compliance_violations"] * 10
        
        return max(0, (pii_score + protection_score + budget_score) / 3 - violation_penalty)
    
    def _calculate_compliance_score(self, compliance_metrics: Dict[str, Any]) -> float:
        """è®¡ç®—åˆè§„è¯„åˆ†"""
        base_score = compliance_metrics["pipl_compliance_rate"] * 100
        violation_penalty = compliance_metrics["total_violations"] * 15
        
        return max(0, base_score - violation_penalty)
    
    def _calculate_workflow_score(self, workflow_metrics: Dict[str, Any]) -> float:
        """è®¡ç®—å·¥ä½œæµè¯„åˆ†"""
        success_score = workflow_metrics["success_rate"] * 100
        time_score = max(0, 100 - workflow_metrics["average_processing_time"] * 50)
        
        return (success_score + time_score) / 2
    
    def _get_overall_status(self, score: float) -> str:
        """è·å–æ€»ä½“çŠ¶æ€"""
        if score >= 90:
            return "excellent"
        elif score >= 80:
            return "good"
        elif score >= 70:
            return "warning"
        else:
            return "critical"
    
    def generate_monitoring_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆç›‘æ§æŠ¥å‘Š"""
        if not self.metrics_history:
            return {"error": "No metrics collected"}
        
        latest_metrics = self.metrics_history[-1]
        
        # è®¡ç®—å†å²è¶‹åŠ¿
        if len(self.metrics_history) > 1:
            system_trend = self._calculate_trend("system_metrics", "overall_score")
            privacy_trend = self._calculate_trend("privacy_metrics", "privacy_score")
            compliance_trend = self._calculate_trend("compliance_metrics", "compliance_score")
            workflow_trend = self._calculate_trend("workflow_metrics", "success_rate")
        else:
            system_trend = privacy_trend = compliance_trend = workflow_trend = "stable"
        
        report = {
            "monitoring_period": {
                "start_time": self.start_time.isoformat(),
                "end_time": datetime.now().isoformat(),
                "duration_minutes": (datetime.now() - self.start_time).total_seconds() / 60
            },
            "current_metrics": latest_metrics,
            "trends": {
                "system_trend": system_trend,
                "privacy_trend": privacy_trend,
                "compliance_trend": compliance_trend,
                "workflow_trend": workflow_trend
            },
            "recommendations": self._generate_recommendations(latest_metrics),
            "alerts": self._generate_alerts(latest_metrics)
        }
        
        return report
    
    def _calculate_trend(self, metric_type: str, metric_name: str) -> str:
        """è®¡ç®—è¶‹åŠ¿"""
        if len(self.metrics_history) < 2:
            return "stable"
        
        recent_values = [metrics[metric_type][metric_name] for metrics in self.metrics_history[-3:]]
        
        if len(recent_values) < 2:
            return "stable"
        
        if recent_values[-1] > recent_values[0] * 1.05:
            return "improving"
        elif recent_values[-1] < recent_values[0] * 0.95:
            return "declining"
        else:
            return "stable"
    
    def _generate_recommendations(self, metrics: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ¨èå»ºè®®"""
        recommendations = []
        
        # ç³»ç»Ÿæ€§èƒ½å»ºè®®
        system = metrics["system_metrics"]
        if system["cpu"]["usage_percent"] > 80:
            recommendations.append("CPUä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®ä¼˜åŒ–ç®—æ³•æˆ–å¢åŠ è®¡ç®—èµ„æº")
        if system["memory"]["usage_percent"] > 80:
            recommendations.append("å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®ä¼˜åŒ–å†…å­˜ä½¿ç”¨æˆ–å¢åŠ å†…å­˜")
        if system["disk"]["usage_percent"] > 80:
            recommendations.append("ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®æ¸…ç†ä¸´æ—¶æ–‡ä»¶æˆ–å¢åŠ å­˜å‚¨ç©ºé—´")
        
        # éšç§ä¿æŠ¤å»ºè®®
        privacy = metrics["privacy_metrics"]
        if privacy["pii_detection_rate"] < 0.9:
            recommendations.append("PIIæ£€æµ‹ç‡åä½ï¼Œå»ºè®®æ”¹è¿›æ£€æµ‹ç®—æ³•")
        if privacy["privacy_budget_usage"] > 0.8:
            recommendations.append("éšç§é¢„ç®—ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®ä¼˜åŒ–éšç§ä¿æŠ¤ç­–ç•¥")
        
        # åˆè§„æ€§å»ºè®®
        compliance = metrics["compliance_metrics"]
        if compliance["total_violations"] > 0:
            recommendations.append("å­˜åœ¨åˆè§„è¿è§„ï¼Œå»ºè®®ç«‹å³å¤„ç†è¿è§„é—®é¢˜")
        
        # å·¥ä½œæµå»ºè®®
        workflow = metrics["workflow_metrics"]
        if workflow["success_rate"] < 0.9:
            recommendations.append("å·¥ä½œæµæˆåŠŸç‡åä½ï¼Œå»ºè®®æ£€æŸ¥å¤„ç†é€»è¾‘")
        if workflow["average_processing_time"] > 0.5:
            recommendations.append("å¹³å‡å¤„ç†æ—¶é—´è¿‡é•¿ï¼Œå»ºè®®ä¼˜åŒ–å¤„ç†æµç¨‹")
        
        return recommendations
    
    def _generate_alerts(self, metrics: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå‘Šè­¦"""
        alerts = []
        
        # ç³»ç»Ÿå‘Šè­¦
        system = metrics["system_metrics"]
        if system["cpu"]["status"] == "critical":
            alerts.append({"type": "system", "level": "critical", "message": "CPUä½¿ç”¨ç‡è¿‡é«˜"})
        if system["memory"]["status"] == "critical":
            alerts.append({"type": "system", "level": "critical", "message": "å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"})
        
        # éšç§å‘Šè­¦
        privacy = metrics["privacy_metrics"]
        if privacy["status"] == "critical":
            alerts.append({"type": "privacy", "level": "critical", "message": "éšç§ä¿æŠ¤çŠ¶æ€å¼‚å¸¸"})
        
        # åˆè§„å‘Šè­¦
        compliance = metrics["compliance_metrics"]
        if compliance["status"] == "non_compliant":
            alerts.append({"type": "compliance", "level": "critical", "message": "åˆè§„æ€§çŠ¶æ€å¼‚å¸¸"})
        
        # å·¥ä½œæµå‘Šè­¦
        workflow = metrics["workflow_metrics"]
        if workflow["status"] == "critical":
            alerts.append({"type": "workflow", "level": "critical", "message": "å·¥ä½œæµçŠ¶æ€å¼‚å¸¸"})
        
        return alerts

def run_performance_monitoring():
    """è¿è¡Œæ€§èƒ½ç›‘æ§"""
    print("ğŸ“Š è¿è¡Œæ€§èƒ½ç›‘æ§...")
    
    # åˆå§‹åŒ–ç›‘æ§å™¨
    monitor_config = {
        "monitoring_interval": 1.0,
        "alert_thresholds": {
            "cpu_usage": 80,
            "memory_usage": 80,
            "disk_usage": 80,
            "gpu_usage": 80
        }
    }
    
    monitor = PerformanceMonitor(monitor_config)
    
    # æ”¶é›†æŒ‡æ ‡
    print("  æ”¶é›†ç³»ç»ŸæŒ‡æ ‡...")
    metrics = monitor.collect_all_metrics()
    
    # ç”Ÿæˆç›‘æ§æŠ¥å‘Š
    print("  ç”Ÿæˆç›‘æ§æŠ¥å‘Š...")
    report = monitor.generate_monitoring_report()
    
    # ä¿å­˜ç›‘æ§ç»“æœ
    metrics_file = "/content/ianvs_pipl_framework/results/performance_metrics.json"
    with open(metrics_file, 'w', encoding='utf-8') as f:
        json.dump(metrics, f, indent=2, ensure_ascii=False)
    
    report_file = "/content/ianvs_pipl_framework/results/monitoring_report.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… æ€§èƒ½ç›‘æ§å®Œæˆ")
    print(f"  ç³»ç»Ÿè¯„åˆ†: {metrics['system_metrics']['cpu']['usage_percent']:.1f}% CPU")
    print(f"  éšç§è¯„åˆ†: {metrics['privacy_metrics']['privacy_score']:.1f}")
    print(f"  åˆè§„è¯„åˆ†: {metrics['compliance_metrics']['compliance_score']:.1f}")
    print(f"  æ€»ä½“è¯„åˆ†: {metrics['overall_score']:.1f} ({metrics['overall_status']})")
    
    return metrics, report

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ é˜¶æ®µ8: æ€§èƒ½ç›‘æ§")
    print("=" * 50)
    
    try:
        # 1. è¿è¡Œæ€§èƒ½ç›‘æ§
        metrics, report = run_performance_monitoring()
        
        # 2. ä¿å­˜ç›‘æ§æŠ¥å‘Š
        monitoring_report = {
            "timestamp": datetime.now().isoformat(),
            "overall_score": metrics["overall_score"],
            "overall_status": metrics["overall_status"],
            "system_metrics": metrics["system_metrics"],
            "privacy_metrics": metrics["privacy_metrics"],
            "compliance_metrics": metrics["compliance_metrics"],
            "workflow_metrics": metrics["workflow_metrics"],
            "recommendations_count": len(report["recommendations"]),
            "alerts_count": len(report["alerts"]),
            "monitoring_status": "success"
        }
        
        report_file = '/content/ianvs_pipl_framework/logs/performance_monitoring_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(monitoring_report, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ… æ€§èƒ½ç›‘æ§å®Œæˆï¼")
        print(f"æ€»ä½“è¯„åˆ†: {metrics['overall_score']:.1f}/100 ({metrics['overall_status']})")
        print(f"ç³»ç»ŸæŒ‡æ ‡: CPU {metrics['system_metrics']['cpu']['usage_percent']:.1f}%, "
              f"å†…å­˜ {metrics['system_metrics']['memory']['usage_percent']:.1f}%")
        print(f"éšç§æŒ‡æ ‡: æ£€æµ‹ç‡ {metrics['privacy_metrics']['pii_detection_rate']:.1%}, "
              f"ä¿æŠ¤ç‡ {metrics['privacy_metrics']['privacy_protection_rate']:.1%}")
        print(f"åˆè§„æŒ‡æ ‡: åˆè§„ç‡ {metrics['compliance_metrics']['pipl_compliance_rate']:.1%}, "
              f"è¿è§„æ•° {metrics['compliance_metrics']['total_violations']}")
        print(f"å·¥ä½œæµæŒ‡æ ‡: æˆåŠŸç‡ {metrics['workflow_metrics']['success_rate']:.1%}, "
              f"å¤„ç†æ—¶é—´ {metrics['workflow_metrics']['average_processing_time']:.3f}s")
        print(f"æ¨èå»ºè®®: {len(report['recommendations'])} æ¡")
        print(f"å‘Šè­¦ä¿¡æ¯: {len(report['alerts'])} æ¡")
        print(f"ç›‘æ§æŠ¥å‘Š: {report_file}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ€§èƒ½ç›‘æ§å¤±è´¥: {e}")
        logger.error(f"æ€§èƒ½ç›‘æ§å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸ‰ é˜¶æ®µ8å®Œæˆï¼Œå¯ä»¥ç»§ç»­æ‰§è¡Œé˜¶æ®µ9")
    else:
        print("\nâŒ é˜¶æ®µ8å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")