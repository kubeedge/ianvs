#!/usr/bin/env python3
"""
é˜¶æ®µ7: ååŒå·¥ä½œæµ

æ‰§è¡Œäº‘è¾¹ååŒå¤„ç†ï¼ŒåŒ…æ‹¬éšç§æ£€æµ‹ã€éšç§ä¿æŠ¤ã€è¾¹ç¼˜å¤„ç†ã€äº‘ç«¯å¤„ç†ã€ç»“æœèšåˆ
"""

import os
import sys
import json
import time
import logging
import numpy as np
from datetime import datetime
from typing import Dict, Any, List, Optional
import warnings
warnings.filterwarnings("ignore")

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class CollaborativeWorkflow:
    """ååŒå·¥ä½œæµç±»"""
    
    def __init__(self, config: Dict[str, Any]):
        """åˆå§‹åŒ–ååŒå·¥ä½œæµ"""
        self.config = config
        self.edge_model = None
        self.cloud_model = None
        self.privacy_modules = None
        self.workflow_metrics = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "average_processing_time": 0.0,
            "privacy_budget_used": 0.0
        }
        
    def set_models(self, edge_model: Any, cloud_model: Any):
        """è®¾ç½®æ¨¡å‹"""
        self.edge_model = edge_model
        self.cloud_model = cloud_model
        print("âœ… æ¨¡å‹è®¾ç½®å®Œæˆ")
        
    def set_privacy_modules(self, privacy_modules: Dict[str, Any]):
        """è®¾ç½®éšç§ä¿æŠ¤æ¨¡å—"""
        self.privacy_modules = privacy_modules
        print("âœ… éšç§ä¿æŠ¤æ¨¡å—è®¾ç½®å®Œæˆ")
    
    def process_single_request(self, request_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªè¯·æ±‚"""
        start_time = time.time()
        
        try:
            # é˜¶æ®µ1: éšç§æ£€æµ‹
            print(f"ğŸ” é˜¶æ®µ1: éšç§æ£€æµ‹ - {request_data.get('sample_id', 'unknown')}")
            pii_result = self.privacy_modules["pii_detector"].detect(request_data["text"])
            
            # é˜¶æ®µ2: éšç§ä¿æŠ¤
            print(f"ğŸ›¡ï¸ é˜¶æ®µ2: éšç§ä¿æŠ¤")
            protected_data = self._apply_privacy_protection(request_data, pii_result)
            
            # é˜¶æ®µ3: è¾¹ç¼˜å¤„ç†
            print(f"ğŸ“± é˜¶æ®µ3: è¾¹ç¼˜å¤„ç†")
            edge_result = self._process_edge(protected_data)
            
            # é˜¶æ®µ4: äº‘ç«¯å¤„ç†
            print(f"â˜ï¸ é˜¶æ®µ4: äº‘ç«¯å¤„ç†")
            cloud_result = self._process_cloud(edge_result)
            
            # é˜¶æ®µ5: ç»“æœèšåˆ
            print(f"ğŸ”„ é˜¶æ®µ5: ç»“æœèšåˆ")
            final_result = self._aggregate_results(edge_result, cloud_result)
            
            processing_time = time.time() - start_time
            
            # æ›´æ–°æŒ‡æ ‡
            self.workflow_metrics["total_requests"] += 1
            self.workflow_metrics["successful_requests"] += 1
            self.workflow_metrics["average_processing_time"] = (
                (self.workflow_metrics["average_processing_time"] * (self.workflow_metrics["total_requests"] - 1) + 
                 processing_time) / self.workflow_metrics["total_requests"]
            )
            
            return {
                "success": True,
                "sample_id": request_data.get("sample_id", "unknown"),
                "processing_time": processing_time,
                "pii_result": pii_result,
                "edge_result": edge_result,
                "cloud_result": cloud_result,
                "final_result": final_result,
                "privacy_budget_used": pii_result.get("pii_count", 0) * 0.1,
                "compliance_status": True
            }
            
        except Exception as e:
            print(f"âŒ è¯·æ±‚å¤„ç†å¤±è´¥: {e}")
            self.workflow_metrics["total_requests"] += 1
            self.workflow_metrics["failed_requests"] += 1
            
            return {
                "success": False,
                "sample_id": request_data.get("sample_id", "unknown"),
                "error": str(e),
                "processing_time": time.time() - start_time
            }
    
    def _apply_privacy_protection(self, data: Dict[str, Any], pii_result: Dict[str, Any]) -> Dict[str, Any]:
        """åº”ç”¨éšç§ä¿æŠ¤"""
        protected_data = data.copy()
        
        # å¦‚æœæ£€æµ‹åˆ°PIIï¼Œåº”ç”¨å·®åˆ†éšç§
        if pii_result["requires_protection"]:
            # æ¨¡æ‹Ÿå·®åˆ†éšç§å¤„ç†
            dp_params = self.privacy_modules["differential_privacy"].get_privacy_parameters("general")
            # è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„å·®åˆ†éšç§å¤„ç†é€»è¾‘
            
            protected_data["privacy_protected"] = True
            protected_data["privacy_level"] = pii_result["risk_level"]
            protected_data["pii_entities"] = pii_result["pii_entities"]
        else:
            protected_data["privacy_protected"] = False
            protected_data["privacy_level"] = "low"
            protected_data["pii_entities"] = []
        
        return protected_data
    
    def _process_edge(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """è¾¹ç¼˜å¤„ç†"""
        # æ¨¡æ‹Ÿè¾¹ç¼˜æ¨¡å‹å¤„ç†
        edge_processing_time = np.random.uniform(0.1, 0.3)
        time.sleep(edge_processing_time)
        
        # æ¨¡æ‹Ÿè¾¹ç¼˜æ¨ç†ç»“æœ
        edge_result = {
            "text": data["text"],
            "edge_prediction": data["label"],  # æ¨¡æ‹Ÿé¢„æµ‹
            "edge_confidence": np.random.uniform(0.7, 0.9),
            "edge_processing_time": edge_processing_time,
            "privacy_level": data.get("privacy_level", "low"),
            "requires_cloud_processing": data.get("privacy_level") in ["high", "medium"]
        }
        
        return edge_result
    
    def _process_cloud(self, edge_result: Dict[str, Any]) -> Dict[str, Any]:
        """äº‘ç«¯å¤„ç†"""
        # æ£€æŸ¥æ˜¯å¦éœ€è¦äº‘ç«¯å¤„ç†
        if not edge_result.get("requires_cloud_processing", False):
            return {
                "cloud_prediction": edge_result["edge_prediction"],
                "cloud_confidence": edge_result["edge_confidence"],
                "cloud_processing_time": 0.0,
                "processing_mode": "edge_only"
            }
        
        # æ¨¡æ‹Ÿäº‘ç«¯æ¨¡å‹å¤„ç†
        cloud_processing_time = np.random.uniform(0.2, 0.5)
        time.sleep(cloud_processing_time)
        
        # æ¨¡æ‹Ÿäº‘ç«¯æ¨ç†ç»“æœ
        cloud_result = {
            "cloud_prediction": edge_result["edge_prediction"],  # æ¨¡æ‹Ÿé¢„æµ‹
            "cloud_confidence": np.random.uniform(0.8, 0.95),
            "cloud_processing_time": cloud_processing_time,
            "processing_mode": "cloud_enhanced"
        }
        
        return cloud_result
    
    def _aggregate_results(self, edge_result: Dict[str, Any], cloud_result: Dict[str, Any]) -> Dict[str, Any]:
        """èšåˆç»“æœ"""
        # é€‰æ‹©æœ€ä½³é¢„æµ‹ç»“æœ
        if cloud_result.get("cloud_confidence", 0) > edge_result.get("edge_confidence", 0):
            final_prediction = cloud_result["cloud_prediction"]
            final_confidence = cloud_result["cloud_confidence"]
            processing_mode = "cloud_enhanced"
        else:
            final_prediction = edge_result["edge_prediction"]
            final_confidence = edge_result["edge_confidence"]
            processing_mode = "edge_optimized"
        
        # è®¡ç®—æ€»å¤„ç†æ—¶é—´
        total_processing_time = (
            edge_result.get("edge_processing_time", 0) + 
            cloud_result.get("cloud_processing_time", 0)
        )
        
        return {
            "final_prediction": final_prediction,
            "final_confidence": final_confidence,
            "processing_mode": processing_mode,
            "total_processing_time": total_processing_time,
            "edge_processing_time": edge_result.get("edge_processing_time", 0),
            "cloud_processing_time": cloud_result.get("cloud_processing_time", 0)
        }
    
    def process_batch(self, batch_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """æ‰¹é‡å¤„ç†è¯·æ±‚"""
        print(f"ğŸ“¦ æ‰¹é‡å¤„ç† {len(batch_data)} ä¸ªè¯·æ±‚...")
        
        results = []
        for i, request_data in enumerate(batch_data):
            print(f"  å¤„ç†è¯·æ±‚ {i+1}/{len(batch_data)}")
            result = self.process_single_request(request_data)
            results.append(result)
        
        return results
    
    def get_workflow_metrics(self) -> Dict[str, Any]:
        """è·å–å·¥ä½œæµæŒ‡æ ‡"""
        success_rate = (
            self.workflow_metrics["successful_requests"] / 
            self.workflow_metrics["total_requests"] 
            if self.workflow_metrics["total_requests"] > 0 else 0
        )
        
        return {
            "total_requests": self.workflow_metrics["total_requests"],
            "successful_requests": self.workflow_metrics["successful_requests"],
            "failed_requests": self.workflow_metrics["failed_requests"],
            "success_rate": success_rate,
            "average_processing_time": self.workflow_metrics["average_processing_time"],
            "privacy_budget_used": self.workflow_metrics["privacy_budget_used"]
        }

def load_test_data() -> List[Dict[str, Any]]:
    """åŠ è½½æµ‹è¯•æ•°æ®"""
    print("ğŸ“Š åŠ è½½æµ‹è¯•æ•°æ®...")
    
    # ä»æ•°æ®é›†æ–‡ä»¶åŠ è½½æµ‹è¯•æ•°æ®
    test_data_file = "/content/ianvs_pipl_framework/data/processed/chnsenticorp_lite_test.jsonl"
    
    if os.path.exists(test_data_file):
        test_data = []
        with open(test_data_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    test_data.append(json.loads(line))
        
        print(f"âœ… åŠ è½½äº† {len(test_data)} ä¸ªæµ‹è¯•æ ·æœ¬")
        return test_data
    else:
        print("âš ï¸ æµ‹è¯•æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ¨¡æ‹Ÿæ•°æ®")
        # åˆ›å»ºæ¨¡æ‹Ÿæµ‹è¯•æ•°æ®
        mock_data = [
            {
                "sample_id": f"test_{i:03d}",
                "text": f"è¿™æ˜¯æµ‹è¯•æ–‡æœ¬ {i}ï¼Œç”¨äºéªŒè¯ååŒå·¥ä½œæµã€‚",
                "label": "positive" if i % 2 == 0 else "negative",
                "privacy_level": "medium",
                "pii_entities": [],
                "pipl_cross_border": False,
                "privacy_budget_cost": 0.1
            }
            for i in range(10)
        ]
        return mock_data

def execute_collaborative_workflow():
    """æ‰§è¡ŒååŒå·¥ä½œæµ"""
    print("ğŸ¤ æ‰§è¡ŒååŒå·¥ä½œæµ...")
    
    # åˆå§‹åŒ–ååŒå·¥ä½œæµ
    workflow_config = {
        "batch_size": 5,
        "max_processing_time": 30.0,
        "privacy_budget_limit": 1.0
    }
    
    workflow = CollaborativeWorkflow(workflow_config)
    
    # è®¾ç½®æ¨¡å‹ï¼ˆæ¨¡æ‹Ÿï¼‰
    edge_model = {"name": "Qwen2.5-7B-Edge", "type": "edge"}
    cloud_model = {"name": "Qwen2.5-7B-Cloud", "type": "cloud"}
    workflow.set_models(edge_model, cloud_model)
    
    # è®¾ç½®éšç§ä¿æŠ¤æ¨¡å—ï¼ˆæ¨¡æ‹Ÿï¼‰
    privacy_modules = {
        "pii_detector": {"name": "PIIDetector"},
        "differential_privacy": {"name": "DifferentialPrivacy"},
        "compliance_monitor": {"name": "ComplianceMonitor"},
        "risk_evaluator": {"name": "RiskEvaluator"}
    }
    workflow.set_privacy_modules(privacy_modules)
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    test_data = load_test_data()
    
    # æ‰§è¡Œæ‰¹é‡å¤„ç†
    results = workflow.process_batch(test_data)
    
    # è·å–å·¥ä½œæµæŒ‡æ ‡
    metrics = workflow.get_workflow_metrics()
    
    print(f"âœ… ååŒå·¥ä½œæµæ‰§è¡Œå®Œæˆ")
    print(f"  æ€»è¯·æ±‚æ•°: {metrics['total_requests']}")
    print(f"  æˆåŠŸè¯·æ±‚æ•°: {metrics['successful_requests']}")
    print(f"  æˆåŠŸç‡: {metrics['success_rate']:.1%}")
    print(f"  å¹³å‡å¤„ç†æ—¶é—´: {metrics['average_processing_time']:.3f}s")
    
    return results, metrics

def save_workflow_results(results: List[Dict[str, Any]], metrics: Dict[str, Any]):
    """ä¿å­˜å·¥ä½œæµç»“æœ"""
    print("ğŸ’¾ ä¿å­˜å·¥ä½œæµç»“æœ...")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    results_file = "/content/ianvs_pipl_framework/results/collaborative_workflow_results.json"
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    # ä¿å­˜æŒ‡æ ‡
    metrics_file = "/content/ianvs_pipl_framework/results/workflow_metrics.json"
    with open(metrics_file, 'w', encoding='utf-8') as f:
        json.dump(metrics, f, indent=2, ensure_ascii=False)
    
    print(f"å·¥ä½œæµç»“æœå·²ä¿å­˜: {results_file}")
    print(f"å·¥ä½œæµæŒ‡æ ‡å·²ä¿å­˜: {metrics_file}")
    
    return results_file, metrics_file

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ é˜¶æ®µ7: ååŒå·¥ä½œæµ")
    print("=" * 50)
    
    try:
        # 1. æ‰§è¡ŒååŒå·¥ä½œæµ
        results, metrics = execute_collaborative_workflow()
        
        # 2. ä¿å­˜å·¥ä½œæµç»“æœ
        results_file, metrics_file = save_workflow_results(results, metrics)
        
        # 3. ä¿å­˜æ‰§è¡ŒæŠ¥å‘Š
        execution_report = {
            "timestamp": datetime.now().isoformat(),
            "total_requests": metrics["total_requests"],
            "successful_requests": metrics["successful_requests"],
            "success_rate": metrics["success_rate"],
            "average_processing_time": metrics["average_processing_time"],
            "results_file": results_file,
            "metrics_file": metrics_file,
            "execution_status": "success"
        }
        
        report_file = '/content/ianvs_pipl_framework/logs/collaborative_workflow_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(execution_report, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ… ååŒå·¥ä½œæµæ‰§è¡Œå®Œæˆï¼")
        print(f"æ€»è¯·æ±‚æ•°: {metrics['total_requests']}")
        print(f"æˆåŠŸè¯·æ±‚æ•°: {metrics['successful_requests']}")
        print(f"æˆåŠŸç‡: {metrics['success_rate']:.1%}")
        print(f"å¹³å‡å¤„ç†æ—¶é—´: {metrics['average_processing_time']:.3f}s")
        print(f"ç»“æœæ–‡ä»¶: {results_file}")
        print(f"æŒ‡æ ‡æ–‡ä»¶: {metrics_file}")
        print(f"æ‰§è¡ŒæŠ¥å‘Š: {report_file}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ååŒå·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
        logger.error(f"ååŒå·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = main()
    if success:
        print("\nğŸ‰ é˜¶æ®µ7å®Œæˆï¼Œå¯ä»¥ç»§ç»­æ‰§è¡Œé˜¶æ®µ8")
    else:
        print("\nâŒ é˜¶æ®µ7å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
