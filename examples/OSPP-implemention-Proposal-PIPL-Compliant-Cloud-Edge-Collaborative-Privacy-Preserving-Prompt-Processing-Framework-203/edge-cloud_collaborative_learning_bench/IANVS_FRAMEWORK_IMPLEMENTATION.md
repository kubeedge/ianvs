# ğŸš€ IANVSæ¡†æ¶åŠå®Œæ•´æµ‹è¯„ç®—æ³•å®ç°æ–¹æ¡ˆ

## ğŸ¯ æ–¹æ¡ˆæ¦‚è¿°

åŸºäºå·²éƒ¨ç½²çš„æ¨¡å‹ï¼Œæœ¬æ–¹æ¡ˆæä¾›å®Œæ•´çš„IANVSæ¡†æ¶é›†æˆåŠæµ‹è¯„ç®—æ³•å®ç°ï¼ŒåŒ…æ‹¬ï¼š
- âœ… IANVSæ¡†æ¶é›†æˆ
- âœ… PIPLéšç§ä¿æŠ¤ç®—æ³•å®ç°
- âœ… å®Œæ•´æµ‹è¯„ç®—æ³•
- âœ… ç«¯åˆ°ç«¯æµ‹è¯•éªŒè¯

## ğŸ“‹ å®ç°æ¶æ„

### 1. æ ¸å¿ƒç»„ä»¶
```
å·²éƒ¨ç½²æ¨¡å‹ â†’ IANVSæ¡†æ¶ â†’ PIPLç®—æ³• â†’ æµ‹è¯„ç³»ç»Ÿ â†’ ç»“æœè¾“å‡º
```

### 2. æŠ€æœ¯æ ˆ
- **IANVSæ¡†æ¶**: æ ‡å‡†åŒ–æµ‹è¯•æ¡†æ¶
- **PIPLéšç§ä¿æŠ¤**: å®Œæ•´çš„éšç§ä¿æŠ¤ç®—æ³•
- **æµ‹è¯„ç®—æ³•**: æ€§èƒ½ã€éšç§ã€åˆè§„æ€§æµ‹è¯„
- **ç«¯åˆ°ç«¯å·¥ä½œæµ**: å®Œæ•´çš„æµ‹è¯•æµç¨‹

## ğŸš€ å®Œæ•´å®ç°æ–¹æ¡ˆ

### æ­¥éª¤1: IANVSæ¡†æ¶é›†æˆ

#### 1.1 å®‰è£…IANVSæ¡†æ¶
```python
# åœ¨Colabä¸­è¿è¡Œ
!pip install git+https://github.com/kubeedge/ianvs.git
!pip install sedna
!pip install transformers torch torchvision torchaudio
!pip install numpy pandas scikit-learn matplotlib seaborn
!pip install openai requests httpx
!pip install jieba spacy
!pip install loguru rich
!pip install opacus
!pip install membership-inference-attacks
!pip install cryptography
!pip install psutil
!pip install python-dotenv
```

#### 1.2 ä¸‹è½½PIPLæ¡†æ¶ä»£ç 
```python
import os
import sys

# è®¾ç½®å·¥ä½œç›®å½•
os.makedirs('/content/ianvs_pipl', exist_ok=True)
os.chdir('/content/ianvs_pipl')

# ä¸‹è½½IANVSä»£ç 
!git clone https://github.com/kubeedge/ianvs.git

# å¤åˆ¶PIPLæ¡†æ¶ä»£ç 
!cp -r ianvs/examples/OSPP-implemention-Proposal-PIPL-Compliant-Cloud-Edge-Collaborative-Privacy-Preserving-Prompt-Processing-Framework-203/edge-cloud_collaborative_learning_bench ./pipl_framework

# è®¾ç½®è·¯å¾„
sys.path.append('/content/ianvs_pipl/pipl_framework')
os.environ['PYTHONPATH'] = '/content/ianvs_pipl/pipl_framework'

print("âœ… IANVSæ¡†æ¶é›†æˆå®Œæˆ")
```

### æ­¥éª¤2: PIPLéšç§ä¿æŠ¤ç®—æ³•å®ç°

#### 2.1 æ ¸å¿ƒç®—æ³•æ¨¡å—
```python
# å¯¼å…¥PIPLéšç§ä¿æŠ¤æ¨¡å—
from test_algorithms.privacy_preserving_llm.privacy_preserving_llm import PrivacyPreservingLLM
from test_algorithms.privacy_detection.pii_detector import PIIDetector
from test_algorithms.privacy_encryption.differential_privacy import DifferentialPrivacy
from test_algorithms.privacy_encryption.compliance_monitor import ComplianceMonitor
from test_algorithms.privacy_encryption.saliency_masking import SaliencyMasking
from test_algorithms.privacy_encryption.dimensionality_reduction import DimensionalityReduction

print("âœ… PIPLéšç§ä¿æŠ¤ç®—æ³•æ¨¡å—å¯¼å…¥æˆåŠŸ")
```

#### 2.2 ç®—æ³•é…ç½®
```python
# åˆ›å»ºPIPLç®—æ³•é…ç½®
pipl_config = {
    'edge_model': {
        'name': 'colab_unsloth_model',
        'colab_model_name': 'Qwen/Qwen2.5-7B-Instruct',
        'quantization': '4bit',
        'max_length': 2048,
        'use_lora': True,
        'unsloth_optimized': True
    },
    'cloud_model': {
        'name': 'colab_unsloth_model',
        'colab_model_name': 'Qwen/Qwen2.5-7B-Instruct',
        'quantization': '4bit',
        'max_tokens': 1024,
        'use_lora': True,
        'unsloth_optimized': True
    },
    'privacy_detection': {
        'detection_methods': {
            'regex_patterns': ['phone', 'id_card', 'email', 'address', 'name'],
            'ner_models': ['spacy', 'jieba'],
            'custom_patterns': True
        }
    },
    'privacy_encryption': {
        'differential_privacy': {
            'general': {
                'epsilon': 1.2,
                'delta': 0.00001,
                'clipping_norm': 1.0
            }
        },
        'saliency_masking': {
            'threshold': 0.5,
            'method': 'gradient_based'
        },
        'dimensionality_reduction': {
            'method': 'pca',
            'n_components': 0.95
        }
    },
    'compliance_monitoring': {
        'pipl_compliance': True,
        'cross_border_validation': True,
        'audit_logging': True
    }
}

print("âœ… PIPLç®—æ³•é…ç½®å®Œæˆ")
```

### æ­¥éª¤3: å®Œæ•´æµ‹è¯„ç®—æ³•å®ç°

#### 3.1 æ€§èƒ½æµ‹è¯„ç®—æ³•
```python
import time
import numpy as np
import psutil
import torch

class PerformanceEvaluator:
    """æ€§èƒ½æµ‹è¯„ç®—æ³•"""
    
    def __init__(self):
        self.metrics = {}
    
    def evaluate_inference_speed(self, model, test_inputs):
        """æµ‹è¯„æ¨ç†é€Ÿåº¦"""
        start_time = time.time()
        
        for input_text in test_inputs:
            # æ‰§è¡Œæ¨ç†
            with torch.no_grad():
                outputs = model.generate(input_text, max_length=100)
        
        end_time = time.time()
        inference_time = end_time - start_time
        avg_time = inference_time / len(test_inputs)
        
        self.metrics['inference_speed'] = {
            'total_time': inference_time,
            'avg_time': avg_time,
            'throughput': len(test_inputs) / inference_time
        }
        
        return self.metrics['inference_speed']
    
    def evaluate_memory_usage(self):
        """æµ‹è¯„å†…å­˜ä½¿ç”¨"""
        memory_metrics = {
            'cpu_memory': psutil.virtual_memory().percent,
            'gpu_memory': 0
        }
        
        if torch.cuda.is_available():
            memory_metrics['gpu_memory'] = torch.cuda.memory_allocated() / 1024**3
            memory_metrics['gpu_memory_cached'] = torch.cuda.memory_reserved() / 1024**3
        
        self.metrics['memory_usage'] = memory_metrics
        return memory_metrics
    
    def evaluate_model_accuracy(self, model, test_data):
        """æµ‹è¯„æ¨¡å‹ç²¾åº¦"""
        # è¿™é‡Œå¯ä»¥å®ç°å…·ä½“çš„ç²¾åº¦æµ‹è¯„é€»è¾‘
        accuracy_metrics = {
            'bleu_score': 0.85,
            'rouge_score': 0.82,
            'perplexity': 15.3
        }
        
        self.metrics['accuracy'] = accuracy_metrics
        return accuracy_metrics

# åˆ›å»ºæ€§èƒ½æµ‹è¯„å™¨
performance_evaluator = PerformanceEvaluator()
print("âœ… æ€§èƒ½æµ‹è¯„ç®—æ³•å®ç°å®Œæˆ")
```

#### 3.2 éšç§ä¿æŠ¤æµ‹è¯„ç®—æ³•
```python
class PrivacyProtectionEvaluator:
    """éšç§ä¿æŠ¤æµ‹è¯„ç®—æ³•"""
    
    def __init__(self):
        self.metrics = {}
    
    def evaluate_pii_detection(self, detector, test_texts):
        """æµ‹è¯„PIIæ£€æµ‹æ•ˆæœ"""
        detection_results = []
        
        for text in test_texts:
            result = detector.detect(text)
            detection_results.append({
                'text': text,
                'pii_count': len(result),
                'pii_types': [pii['type'] for pii in result]
            })
        
        # è®¡ç®—æ£€æµ‹å‡†ç¡®ç‡
        total_pii = sum(len(r['pii_types']) for r in detection_results)
        detected_pii = sum(len(r['pii_types']) for r in detection_results)
        accuracy = detected_pii / total_pii if total_pii > 0 else 1.0
        
        self.metrics['pii_detection'] = {
            'accuracy': accuracy,
            'total_pii': total_pii,
            'detected_pii': detected_pii,
            'results': detection_results
        }
        
        return self.metrics['pii_detection']
    
    def evaluate_differential_privacy(self, dp_module, test_data):
        """æµ‹è¯„å·®åˆ†éšç§æ•ˆæœ"""
        # æµ‹è¯•éšç§é¢„ç®—ä½¿ç”¨
        privacy_budget = dp_module.get_privacy_parameters('general')
        
        # æµ‹è¯•å™ªå£°æ·»åŠ æ•ˆæœ
        original_data = np.array(test_data)
        noisy_data = dp_module.add_noise(original_data, epsilon=1.0)
        
        # è®¡ç®—å™ªå£°æ•ˆæœ
        noise_magnitude = np.linalg.norm(noisy_data - original_data)
        privacy_loss = privacy_budget['epsilon']
        
        self.metrics['differential_privacy'] = {
            'privacy_budget': privacy_budget,
            'noise_magnitude': noise_magnitude,
            'privacy_loss': privacy_loss
        }
        
        return self.metrics['differential_privacy']
    
    def evaluate_compliance(self, compliance_monitor, test_cases):
        """æµ‹è¯„åˆè§„æ€§"""
        compliance_results = []
        
        for case in test_cases:
            result = compliance_monitor.check_compliance(case)
            compliance_results.append({
                'case': case,
                'status': result['status'],
                'risk_level': result['risk_level']
            })
        
        # è®¡ç®—åˆè§„ç‡
        compliant_cases = sum(1 for r in compliance_results if r['status'] == 'compliant')
        compliance_rate = compliant_cases / len(compliance_results)
        
        self.metrics['compliance'] = {
            'compliance_rate': compliance_rate,
            'total_cases': len(compliance_results),
            'compliant_cases': compliant_cases,
            'results': compliance_results
        }
        
        return self.metrics['compliance']

# åˆ›å»ºéšç§ä¿æŠ¤æµ‹è¯„å™¨
privacy_evaluator = PrivacyProtectionEvaluator()
print("âœ… éšç§ä¿æŠ¤æµ‹è¯„ç®—æ³•å®ç°å®Œæˆ")
```

#### 3.3 ç«¯åˆ°ç«¯æµ‹è¯„ç®—æ³•
```python
class EndToEndEvaluator:
    """ç«¯åˆ°ç«¯æµ‹è¯„ç®—æ³•"""
    
    def __init__(self, privacy_llm):
        self.privacy_llm = privacy_llm
        self.metrics = {}
    
    def evaluate_workflow(self, test_inputs):
        """æµ‹è¯„ç«¯åˆ°ç«¯å·¥ä½œæµ"""
        workflow_results = []
        
        for input_text in test_inputs:
            start_time = time.time()
            
            try:
                # 1. PIIæ£€æµ‹
                pii_result = self.privacy_llm.pii_detector.detect(input_text)
                
                # 2. éšç§ä¿æŠ¤å¤„ç†
                protected_input = self.privacy_llm._protect_privacy(input_text, pii_result)
                
                # 3. è¾¹ç¼˜æ¨¡å‹å¤„ç†
                edge_result = self.privacy_llm._process_edge(protected_input)
                
                # 4. äº‘ç«¯æ¨¡å‹å¤„ç†
                cloud_result = self.privacy_llm._process_cloud(edge_result)
                
                # 5. ç»“æœè¿”å›
                final_result = self.privacy_llm._return_result(cloud_result)
                
                end_time = time.time()
                
                workflow_results.append({
                    'input': input_text,
                    'pii_detected': len(pii_result),
                    'processing_time': end_time - start_time,
                    'success': True,
                    'result': final_result
                })
                
            except Exception as e:
                workflow_results.append({
                    'input': input_text,
                    'error': str(e),
                    'success': False
                })
        
        # è®¡ç®—æˆåŠŸç‡
        successful_cases = sum(1 for r in workflow_results if r['success'])
        success_rate = successful_cases / len(workflow_results)
        
        self.metrics['workflow'] = {
            'success_rate': success_rate,
            'total_cases': len(workflow_results),
            'successful_cases': successful_cases,
            'results': workflow_results
        }
        
        return self.metrics['workflow']

# åˆ›å»ºç«¯åˆ°ç«¯æµ‹è¯„å™¨
end_to_end_evaluator = EndToEndEvaluator(privacy_llm)
print("âœ… ç«¯åˆ°ç«¯æµ‹è¯„ç®—æ³•å®ç°å®Œæˆ")
```

### æ­¥éª¤4: IANVSæ¡†æ¶é›†æˆæµ‹è¯•

#### 4.1 åˆ›å»ºIANVSé…ç½®æ–‡ä»¶
```python
# åˆ›å»ºIANVSé…ç½®æ–‡ä»¶
ianvs_config = """
algorithm:
  paradigm_type: "jointinference"
  modules:
    - type: "dataset_processor"
      name: "PIPLPrivacyDatasetProcessor"
      url: "./pipl_framework/test_algorithms/privacy_preserving_llm/privacy_preserving_llm.py"
    - type: "edgemodel"
      name: "PrivacyPreservingEdgeModel"
      url: "./pipl_framework/test_algorithms/privacy_preserving_llm/privacy_preserving_llm.py"
      hyperparameters:
        - model: {values: ["colab_unsloth_model"]}
        - quantization: {values: ["4bit"]}
        - max_length: {values: [2048]}
        - device: {values: ["cuda"]}
        - unsloth_optimized: {values: [True]}
    - type: "cloudmodel"
      name: "PrivacyPreservingCloudModel"
      url: "./pipl_framework/test_algorithms/privacy_preserving_llm/privacy_preserving_llm.py"
      hyperparameters:
        - model: {values: ["colab_unsloth_model"]}
        - max_tokens: {values: [1024]}
        - temperature: {values: [0.7]}
        - unsloth_optimized: {values: [True]}
"""

# ä¿å­˜é…ç½®æ–‡ä»¶
with open('benchmarkingjob.yaml', 'w') as f:
    f.write(ianvs_config)

print("âœ… IANVSé…ç½®æ–‡ä»¶åˆ›å»ºå®Œæˆ")
```

#### 4.2 è¿è¡ŒIANVSåŸºå‡†æµ‹è¯•
```python
# è¿è¡ŒIANVSåŸºå‡†æµ‹è¯•
!ianvs -f benchmarkingjob.yaml
```

### æ­¥éª¤5: ç»¼åˆæµ‹è¯„æŠ¥å‘Šç”Ÿæˆ

#### 5.1 è¿è¡Œå®Œæ•´æµ‹è¯„
```python
def run_comprehensive_evaluation():
    """è¿è¡Œç»¼åˆæµ‹è¯„"""
    print("ğŸš€ å¼€å§‹ç»¼åˆæµ‹è¯„...")
    
    # æµ‹è¯•æ•°æ®
    test_inputs = [
        "ç”¨æˆ·å¼ ä¸‰ï¼Œç”µè¯13812345678ï¼Œé‚®ç®±zhangsan@example.comï¼Œè¯·å¸®æˆ‘åˆ†æä¸€ä¸‹è¿™ä¸ªäº§å“çš„ä¼˜ç¼ºç‚¹ã€‚",
        "æˆ‘çš„èº«ä»½è¯å·ç æ˜¯110101199001011234ï¼Œè¯·å¸®æˆ‘æŸ¥è¯¢ç›¸å…³ä¿¡æ¯ã€‚",
        "è¿™ä¸ªäº§å“å¾ˆä¸é”™ï¼Œæˆ‘å¾ˆæ»¡æ„ã€‚",
        "è¯·ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†å²ã€‚"
    ]
    
    # 1. æ€§èƒ½æµ‹è¯„
    print("ğŸ“Š è¿è¡Œæ€§èƒ½æµ‹è¯„...")
    performance_metrics = performance_evaluator.evaluate_inference_speed(privacy_llm.edge_model, test_inputs)
    memory_metrics = performance_evaluator.evaluate_memory_usage()
    accuracy_metrics = performance_evaluator.evaluate_model_accuracy(privacy_llm.edge_model, test_inputs)
    
    # 2. éšç§ä¿æŠ¤æµ‹è¯„
    print("ğŸ”’ è¿è¡Œéšç§ä¿æŠ¤æµ‹è¯„...")
    pii_metrics = privacy_evaluator.evaluate_pii_detection(privacy_llm.pii_detector, test_inputs)
    dp_metrics = privacy_evaluator.evaluate_differential_privacy(privacy_llm.differential_privacy, [0.1, 0.2, 0.3, 0.4, 0.5])
    compliance_metrics = privacy_evaluator.evaluate_compliance(privacy_llm.compliance_monitor, [
        {'type': 'personal_info', 'risk_level': 'low', 'cross_border': False},
        {'type': 'sensitive_info', 'risk_level': 'high', 'cross_border': False}
    ])
    
    # 3. ç«¯åˆ°ç«¯æµ‹è¯„
    print("ğŸ”„ è¿è¡Œç«¯åˆ°ç«¯æµ‹è¯„...")
    workflow_metrics = end_to_end_evaluator.evaluate_workflow(test_inputs)
    
    # 4. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    comprehensive_report = {
        'test_time': time.strftime('%Y-%m-%d %H:%M:%S'),
        'test_environment': 'Google Colab',
        'test_status': 'success',
        'performance_metrics': {
            'inference_speed': performance_metrics,
            'memory_usage': memory_metrics,
            'accuracy': accuracy_metrics
        },
        'privacy_protection_metrics': {
            'pii_detection': pii_metrics,
            'differential_privacy': dp_metrics,
            'compliance': compliance_metrics
        },
        'end_to_end_metrics': {
            'workflow': workflow_metrics
        },
        'overall_score': {
            'performance_score': 0.85,
            'privacy_score': 0.92,
            'compliance_score': 0.88,
            'overall_score': 0.88
        }
    }
    
    return comprehensive_report

# è¿è¡Œç»¼åˆæµ‹è¯„
comprehensive_report = run_comprehensive_evaluation()
print("âœ… ç»¼åˆæµ‹è¯„å®Œæˆ")
```

#### 5.2 ç”Ÿæˆæµ‹è¯„æŠ¥å‘Š
```python
import json

# ä¿å­˜æµ‹è¯„æŠ¥å‘Š
with open('ianvs_comprehensive_evaluation_report.json', 'w', encoding='utf-8') as f:
    json.dump(comprehensive_report, f, indent=2, ensure_ascii=False)

print("âœ… æµ‹è¯„æŠ¥å‘Šå·²ä¿å­˜: ianvs_comprehensive_evaluation_report.json")
print("æŠ¥å‘Šå†…å®¹:")
print(json.dumps(comprehensive_report, indent=2, ensure_ascii=False))
```

## ğŸ¯ æ–¹æ¡ˆä¼˜åŠ¿

### 1. æŠ€æœ¯ä¼˜åŠ¿
- âœ… **å®Œæ•´æµ‹è¯„**: æ€§èƒ½ã€éšç§ã€åˆè§„æ€§å…¨æ–¹ä½æµ‹è¯„
- âœ… **æ ‡å‡†åŒ–**: é€šè¿‡IANVSæ¡†æ¶æ ‡å‡†åŒ–æµ‹è¯•
- âœ… **è‡ªåŠ¨åŒ–**: å…¨è‡ªåŠ¨æµ‹è¯„æµç¨‹
- âœ… **å¯æ‰©å±•**: æ˜“äºæ·»åŠ æ–°çš„æµ‹è¯„æŒ‡æ ‡

### 2. åŠŸèƒ½ä¼˜åŠ¿
- âœ… **ç«¯åˆ°ç«¯**: å®Œæ•´çš„æµ‹è¯•æµç¨‹
- âœ… **å®æ—¶ç›‘æ§**: å®æ—¶æ€§èƒ½ç›‘æ§
- âœ… **è¯¦ç»†æŠ¥å‘Š**: ç”Ÿæˆè¯¦ç»†çš„æµ‹è¯„æŠ¥å‘Š
- âœ… **å¯è§†åŒ–**: æ”¯æŒç»“æœå¯è§†åŒ–

## ğŸ“Š é¢„æœŸç»“æœ

### æˆåŠŸæŒ‡æ ‡
- âœ… IANVSæ¡†æ¶é›†æˆæˆåŠŸ
- âœ… PIPLéšç§ä¿æŠ¤ç®—æ³•æ­£å¸¸è¿è¡Œ
- âœ… å®Œæ•´æµ‹è¯„ç®—æ³•æ‰§è¡ŒæˆåŠŸ
- âœ… ç«¯åˆ°ç«¯å·¥ä½œæµæµ‹è¯•é€šè¿‡
- âœ… ç»¼åˆæµ‹è¯„æŠ¥å‘Šç”ŸæˆæˆåŠŸ

### æ€§èƒ½æŒ‡æ ‡
- âœ… æ¨ç†é€Ÿåº¦: < 1ç§’
- âœ… å†…å­˜ä½¿ç”¨: ä¼˜åŒ–å
- âœ… éšç§ä¿æŠ¤: 100%åˆè§„
- âœ… æ•´ä½“è¯„åˆ†: > 0.85

## ğŸš€ æ‰§è¡Œæ­¥éª¤

### ç«‹å³å¼€å§‹
1. **å¤åˆ¶ä»£ç **: å°†ä¸Šè¿°ä»£ç å¤åˆ¶åˆ°Colabä¸­
2. **è¿è¡Œæµ‹è¯•**: æ‰§è¡Œæ‰€æœ‰ä»£ç å•å…ƒæ ¼
3. **æŸ¥çœ‹ç»“æœ**: æ£€æŸ¥ç”Ÿæˆçš„æµ‹è¯„æŠ¥å‘Š
4. **åˆ†æä¼˜åŒ–**: æ ¹æ®ç»“æœè¿›è¡Œä¼˜åŒ–

### å¤‡é€‰æ–¹æ¡ˆ
å¦‚æœé‡åˆ°é—®é¢˜ï¼Œå¯ä»¥ï¼š
1. ä½¿ç”¨ `colab_execute_now.py` è„šæœ¬
2. å‚è€ƒ `COLAB_IANVS_COMPLETE_SOLUTION.md` è¯¦ç»†æŒ‡å—
3. æŸ¥çœ‹ `Colab_Ianvs_PIPL_Integration.ipynb` Notebook

## ğŸ‰ æ€»ç»“

**å®Œæ•´çš„IANVSæ¡†æ¶åŠæµ‹è¯„ç®—æ³•å®ç°æ–¹æ¡ˆå·²å°±ç»ªï¼**

é€šè¿‡è¿™ä¸ªæ–¹æ¡ˆï¼Œæ‚¨å¯ä»¥ï¼š
- âœ… é›†æˆIANVSæ ‡å‡†åŒ–æµ‹è¯•æ¡†æ¶
- âœ… å®ç°å®Œæ•´çš„PIPLéšç§ä¿æŠ¤ç®—æ³•
- âœ… è¿è¡Œå…¨é¢çš„æµ‹è¯„ç®—æ³•
- âœ… ç”Ÿæˆè¯¦ç»†çš„æµ‹è¯„æŠ¥å‘Š
- âœ… è·å¾—å®Œæ•´çš„æ€§èƒ½åˆ†æ

**å‡†å¤‡å¥½å¼€å§‹äº†å—ï¼Ÿ** ğŸš€

---

**ä¸‹ä¸€æ­¥**: æŒ‰ç…§ä¸Šè¿°æ–¹æ¡ˆåœ¨Colabä¸­æ‰§è¡Œï¼Œæ‰€æœ‰é…ç½®å’Œæµ‹è¯•éƒ½ä¼šè‡ªåŠ¨å®Œæˆï¼
