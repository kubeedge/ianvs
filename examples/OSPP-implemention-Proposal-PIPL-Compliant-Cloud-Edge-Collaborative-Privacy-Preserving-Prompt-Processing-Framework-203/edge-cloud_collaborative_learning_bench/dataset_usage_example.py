#!/usr/bin/env python3
"""
ChnSentiCorp-Liteæ•°æ®é›†ä½¿ç”¨ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•ä½¿ç”¨PIPLåˆè§„çš„äº‘è¾¹ååŒLLMåŸºå‡†æ•°æ®é›†
"""

import json
import random
from pathlib import Path
from typing import Dict, List, Any
import numpy as np

class DatasetUsageExample:
    """æ•°æ®é›†ä½¿ç”¨ç¤ºä¾‹"""
    
    def __init__(self, data_dir: str = "./data/chnsenticorp_lite"):
        self.data_dir = Path(data_dir)
    
    def load_dataset(self) -> Dict[str, List[Dict]]:
        """åŠ è½½æ•°æ®é›†"""
        print("åŠ è½½ChnSentiCorp-Liteæ•°æ®é›†...")
        
        dataset = {}
        for split in ["train", "val", "test"]:
            file_path = self.data_dir / f"{split}.jsonl"
            with open(file_path, "r", encoding="utf-8") as f:
                dataset[split] = [json.loads(line) for line in f]
            print(f"  {split}: {len(dataset[split])} ä¸ªæ ·æœ¬")
        
        return dataset
    
    def demonstrate_privacy_levels(self, dataset: Dict[str, List[Dict]]):
        """æ¼”ç¤ºéšç§çº§åˆ«å¤„ç†"""
        print("\nğŸ”’ éšç§çº§åˆ«å¤„ç†æ¼”ç¤º")
        print("="*50)
        
        # ç»Ÿè®¡éšç§çº§åˆ«åˆ†å¸ƒ
        privacy_levels = {}
        for split, data in dataset.items():
            for sample in data:
                level = sample["privacy_level"]
                privacy_levels[level] = privacy_levels.get(level, 0) + 1
        
        print("éšç§çº§åˆ«åˆ†å¸ƒ:")
        for level, count in privacy_levels.items():
            print(f"  {level}: {count} ä¸ªæ ·æœ¬")
        
        # å±•ç¤ºä¸åŒéšç§çº§åˆ«çš„æ ·æœ¬
        print("\né€šç”¨æ•æ„Ÿåº¦æ ·æœ¬ç¤ºä¾‹:")
        general_samples = [s for s in dataset["train"] if s["privacy_level"] == "general"][:3]
        for i, sample in enumerate(general_samples):
            print(f"  æ ·æœ¬{i+1}: {sample['text']}")
            print(f"    æ ‡ç­¾: {sample['label']}")
            print(f"    è·¨å¢ƒä¼ è¾“: {sample['pipl_cross_border']}")
            print(f"    éšç§é¢„ç®—æˆæœ¬: {sample['privacy_budget_cost']}")
        
        print("\né«˜æ•æ„Ÿåº¦æ ·æœ¬ç¤ºä¾‹:")
        high_sensitivity_samples = [s for s in dataset["train"] if s["privacy_level"] == "high_sensitivity"][:3]
        for i, sample in enumerate(high_sensitivity_samples):
            print(f"  æ ·æœ¬{i+1}: {sample['text']}")
            print(f"    æ ‡ç­¾: {sample['label']}")
            print(f"    PIIå®ä½“: {sample['pii_entities']}")
            print(f"    è·¨å¢ƒä¼ è¾“: {sample['pipl_cross_border']}")
            print(f"    éšç§é¢„ç®—æˆæœ¬: {sample['privacy_budget_cost']}")
            if sample["synthetic_pii"]:
                print(f"    åˆæˆPII: {sample['synthetic_pii']}")
    
    def demonstrate_pii_detection(self, dataset: Dict[str, List[Dict]]):
        """æ¼”ç¤ºPIIæ£€æµ‹"""
        print("\nğŸ” PIIæ£€æµ‹æ¼”ç¤º")
        print("="*50)
        
        # ç»Ÿè®¡PIIå®ä½“åˆ†å¸ƒ
        pii_entities = {}
        for split, data in dataset.items():
            for sample in data:
                for entity in sample["pii_entities"]:
                    pii_entities[entity] = pii_entities.get(entity, 0) + 1
        
        print("PIIå®ä½“åˆ†å¸ƒ:")
        for entity, count in pii_entities.items():
            print(f"  {entity}: {count} ä¸ª")
        
        # å±•ç¤ºåŒ…å«PIIçš„æ ·æœ¬
        print("\nåŒ…å«PIIçš„æ ·æœ¬:")
        pii_samples = []
        for split, data in dataset.items():
            for sample in data:
                if sample["pii_entities"]:
                    pii_samples.append(sample)
                    if len(pii_samples) >= 5:
                        break
            if len(pii_samples) >= 5:
                break
        
        for i, sample in enumerate(pii_samples):
            print(f"  æ ·æœ¬{i+1}: {sample['text']}")
            print(f"    PIIå®ä½“: {sample['pii_entities']}")
            print(f"    éšç§çº§åˆ«: {sample['privacy_level']}")
            print(f"    è·¨å¢ƒä¼ è¾“: {sample['pipl_cross_border']}")
    
    def demonstrate_cross_border_compliance(self, dataset: Dict[str, List[Dict]]):
        """æ¼”ç¤ºè·¨å¢ƒä¼ è¾“åˆè§„æ€§"""
        print("\nğŸŒ è·¨å¢ƒä¼ è¾“åˆè§„æ€§æ¼”ç¤º")
        print("="*50)
        
        # ç»Ÿè®¡è·¨å¢ƒä¼ è¾“åˆ†å¸ƒ
        cross_border_stats = {
            "total_samples": 0,
            "cross_border_allowed": 0,
            "cross_border_denied": 0,
            "high_sensitivity_cross_border": 0
        }
        
        for split, data in dataset.items():
            for sample in data:
                cross_border_stats["total_samples"] += 1
                
                if sample["pipl_cross_border"]:
                    cross_border_stats["cross_border_allowed"] += 1
                    
                    # æ£€æŸ¥é«˜æ•æ„Ÿåº¦æ•°æ®æ˜¯å¦é”™è¯¯åœ°å…è®¸è·¨å¢ƒä¼ è¾“
                    if sample["privacy_level"] == "high_sensitivity":
                        cross_border_stats["high_sensitivity_cross_border"] += 1
                else:
                    cross_border_stats["cross_border_denied"] += 1
        
        print("è·¨å¢ƒä¼ è¾“ç»Ÿè®¡:")
        print(f"  æ€»æ ·æœ¬æ•°: {cross_border_stats['total_samples']}")
        print(f"  å…è®¸è·¨å¢ƒ: {cross_border_stats['cross_border_allowed']}")
        print(f"  ç¦æ­¢è·¨å¢ƒ: {cross_border_stats['cross_border_denied']}")
        print(f"  é«˜æ•æ„Ÿåº¦é”™è¯¯è·¨å¢ƒ: {cross_border_stats['high_sensitivity_cross_border']}")
        
        # å±•ç¤ºåˆè§„æ€§æ£€æŸ¥
        print("\nåˆè§„æ€§æ£€æŸ¥ç¤ºä¾‹:")
        compliance_samples = []
        for split, data in dataset.items():
            for sample in data:
                if sample["privacy_level"] == "high_sensitivity" and sample["pipl_cross_border"]:
                    compliance_samples.append(sample)
                    if len(compliance_samples) >= 3:
                        break
            if len(compliance_samples) >= 3:
                break
        
        if compliance_samples:
            print("  å‘ç°åˆè§„æ€§é—®é¢˜:")
            for i, sample in enumerate(compliance_samples):
                print(f"    æ ·æœ¬{i+1}: {sample['text']}")
                print(f"      éšç§çº§åˆ«: {sample['privacy_level']}")
                print(f"      è·¨å¢ƒä¼ è¾“: {sample['pipl_cross_border']}")
                print(f"      é—®é¢˜: é«˜æ•æ„Ÿåº¦æ•°æ®ä¸åº”å…è®¸è·¨å¢ƒä¼ è¾“")
        else:
            print("  âœ… æœªå‘ç°åˆè§„æ€§é—®é¢˜")
    
    def demonstrate_privacy_budget_management(self, dataset: Dict[str, List[Dict]]):
        """æ¼”ç¤ºéšç§é¢„ç®—ç®¡ç†"""
        print("\nğŸ’° éšç§é¢„ç®—ç®¡ç†æ¼”ç¤º")
        print("="*50)
        
        # ç»Ÿè®¡éšç§é¢„ç®—æˆæœ¬
        budget_costs = []
        for split, data in dataset.items():
            for sample in data:
                budget_costs.append(sample["privacy_budget_cost"])
        
        print("éšç§é¢„ç®—æˆæœ¬ç»Ÿè®¡:")
        print(f"  å‡å€¼: {np.mean(budget_costs):.3f}")
        print(f"  æ ‡å‡†å·®: {np.std(budget_costs):.3f}")
        print(f"  æœ€å°å€¼: {np.min(budget_costs):.3f}")
        print(f"  æœ€å¤§å€¼: {np.max(budget_costs):.3f}")
        
        # æŒ‰éšç§çº§åˆ«åˆ†æé¢„ç®—æˆæœ¬
        print("\næŒ‰éšç§çº§åˆ«åˆ†æé¢„ç®—æˆæœ¬:")
        for level in ["general", "high_sensitivity"]:
            level_costs = []
            for split, data in dataset.items():
                for sample in data:
                    if sample["privacy_level"] == level:
                        level_costs.append(sample["privacy_budget_cost"])
            
            if level_costs:
                print(f"  {level}:")
                print(f"    å‡å€¼: {np.mean(level_costs):.3f}")
                print(f"    æ ‡å‡†å·®: {np.std(level_costs):.3f}")
                print(f"    æ ·æœ¬æ•°: {len(level_costs)}")
        
        # å±•ç¤ºé«˜é¢„ç®—æˆæœ¬æ ·æœ¬
        print("\né«˜é¢„ç®—æˆæœ¬æ ·æœ¬ç¤ºä¾‹:")
        high_budget_samples = sorted(dataset["train"], key=lambda x: x["privacy_budget_cost"], reverse=True)[:3]
        for i, sample in enumerate(high_budget_samples):
            print(f"  æ ·æœ¬{i+1}: {sample['text']}")
            print(f"    éšç§çº§åˆ«: {sample['privacy_level']}")
            print(f"    PIIå®ä½“: {sample['pii_entities']}")
            print(f"    é¢„ç®—æˆæœ¬: {sample['privacy_budget_cost']}")
    
    def demonstrate_mia_test_subset(self, dataset: Dict[str, List[Dict]]):
        """æ¼”ç¤ºMIAæµ‹è¯•å­é›†"""
        print("\nğŸ¯ MIAæµ‹è¯•å­é›†æ¼”ç¤º")
        print("="*50)
        
        # ç»Ÿè®¡MIAæµ‹è¯•å­é›†
        mia_stats = {
            "total_samples": 0,
            "mia_test_samples": 0,
            "mia_test_by_privacy_level": {}
        }
        
        for split, data in dataset.items():
            for sample in data:
                mia_stats["total_samples"] += 1
                
                if sample["metadata"].get("mia_test_subset", False):
                    mia_stats["mia_test_samples"] += 1
                    
                    level = sample["privacy_level"]
                    mia_stats["mia_test_by_privacy_level"][level] = mia_stats["mia_test_by_privacy_level"].get(level, 0) + 1
        
        print("MIAæµ‹è¯•å­é›†ç»Ÿè®¡:")
        print(f"  æ€»æ ·æœ¬æ•°: {mia_stats['total_samples']}")
        print(f"  MIAæµ‹è¯•æ ·æœ¬: {mia_stats['mia_test_samples']}")
        print(f"  MIAæµ‹è¯•æ¯”ä¾‹: {mia_stats['mia_test_samples'] / mia_stats['total_samples']:.3f}")
        
        print("\næŒ‰éšç§çº§åˆ«çš„MIAæµ‹è¯•æ ·æœ¬:")
        for level, count in mia_stats["mia_test_by_privacy_level"].items():
            print(f"  {level}: {count} ä¸ª")
        
        # å±•ç¤ºMIAæµ‹è¯•æ ·æœ¬
        print("\nMIAæµ‹è¯•æ ·æœ¬ç¤ºä¾‹:")
        mia_samples = []
        for split, data in dataset.items():
            for sample in data:
                if sample["metadata"].get("mia_test_subset", False):
                    mia_samples.append(sample)
                    if len(mia_samples) >= 3:
                        break
            if len(mia_samples) >= 3:
                break
        
        for i, sample in enumerate(mia_samples):
            print(f"  æ ·æœ¬{i+1}: {sample['text']}")
            print(f"    éšç§çº§åˆ«: {sample['privacy_level']}")
            print(f"    PIIå®ä½“: {sample['pii_entities']}")
            print(f"    è·¨å¢ƒä¼ è¾“: {sample['pipl_cross_border']}")
            print(f"    é¢„ç®—æˆæœ¬: {sample['privacy_budget_cost']}")
    
    def demonstrate_dataset_usage(self, dataset: Dict[str, List[Dict]]):
        """æ¼”ç¤ºæ•°æ®é›†ä½¿ç”¨"""
        print("\nğŸ“Š æ•°æ®é›†ä½¿ç”¨æ¼”ç¤º")
        print("="*50)
        
        # å±•ç¤ºæ•°æ®é›†åŸºæœ¬ä¿¡æ¯
        print("æ•°æ®é›†åŸºæœ¬ä¿¡æ¯:")
        for split, data in dataset.items():
            print(f"  {split}: {len(data)} ä¸ªæ ·æœ¬")
        
        # å±•ç¤ºæ ‡ç­¾åˆ†å¸ƒ
        print("\næ ‡ç­¾åˆ†å¸ƒ:")
        label_dist = {}
        for split, data in dataset.items():
            for sample in data:
                label = sample["label"]
                label_dist[label] = label_dist.get(label, 0) + 1
        
        for label, count in label_dist.items():
            print(f"  {label}: {count} ä¸ª")
        
        # å±•ç¤ºæ•°æ®æºåˆ†å¸ƒ
        print("\næ•°æ®æºåˆ†å¸ƒ:")
        source_dist = {}
        for split, data in dataset.items():
            for sample in data:
                source = sample["metadata"].get("source", "unknown")
                source_dist[source] = source_dist.get(source, 0) + 1
        
        for source, count in source_dist.items():
            print(f"  {source}: {count} ä¸ª")
        
        # å±•ç¤ºé¢†åŸŸåˆ†å¸ƒ
        print("\né¢†åŸŸåˆ†å¸ƒ:")
        domain_dist = {}
        for split, data in dataset.items():
            for sample in data:
                domain = sample["metadata"].get("domain", "unknown")
                domain_dist[domain] = domain_dist.get(domain, 0) + 1
        
        for domain, count in domain_dist.items():
            print(f"  {domain}: {count} ä¸ª")
    
    def run_demonstration(self):
        """è¿è¡Œå®Œæ•´æ¼”ç¤º"""
        print("ChnSentiCorp-Liteæ•°æ®é›†ä½¿ç”¨æ¼”ç¤º")
        print("å±•ç¤ºPIPLåˆè§„çš„äº‘è¾¹ååŒLLMåŸºå‡†æ•°æ®é›†")
        print("="*60)
        
        # åŠ è½½æ•°æ®é›†
        dataset = self.load_dataset()
        
        # æ¼”ç¤ºå„ç§åŠŸèƒ½
        self.demonstrate_privacy_levels(dataset)
        self.demonstrate_pii_detection(dataset)
        self.demonstrate_cross_border_compliance(dataset)
        self.demonstrate_privacy_budget_management(dataset)
        self.demonstrate_mia_test_subset(dataset)
        self.demonstrate_dataset_usage(dataset)
        
        print("\nğŸ‰ æ•°æ®é›†ä½¿ç”¨æ¼”ç¤ºå®Œæˆï¼")
        print("æ•°æ®é›†å·²å‡†å¤‡å¥½ç”¨äºPIPLåˆè§„çš„äº‘è¾¹ååŒLLMåŸºå‡†æµ‹è¯•")

def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºä½¿ç”¨ç¤ºä¾‹
    example = DatasetUsageExample()
    
    # è¿è¡Œæ¼”ç¤º
    example.run_demonstration()

if __name__ == "__main__":
    main()
