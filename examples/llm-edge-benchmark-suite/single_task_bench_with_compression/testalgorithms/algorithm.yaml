<<<<<<< HEAD
algorithm:
  paradigm_type: "singletasklearning_with_compression"
  mode: "with_compression"
  initial_model_url: "models/qwen/qwen_1_5_0_5b.gguf"
  quantization_type: "q8_0"
  llama_quantize_path: "llama.cpp/llama-quantize"
  modules:
    - type: "basemodel"
      name: "LlamaCppModel"
      url: "./examples/llm-edge-benchmark-suite/single_task_bench_with_compression/testalgorithms/basemodel.py"
      
      hyperparameters:
        - model_path:
            values:
              - "models/qwen/qwen_1_5_0_5b.gguf"
        - n_ctx:
            values:
              - 2048
=======
version https://git-lfs.github.com/spec/v1
oid sha256:15fac00dd36839425510efa199524956c0732e314f12ce5d129822cd5393fbab
size 578
>>>>>>> 9676c3e (ya toh aar ya toh par)
